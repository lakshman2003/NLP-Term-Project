{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c54b86e79114e78af92a229fd40e298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05f7ed81ad7346758a7b71eaef5dbe52",
              "IPY_MODEL_a5916dc7e87844b2b582cb790638db55",
              "IPY_MODEL_dc56be297cad499eaca6ef0c56aff181"
            ],
            "layout": "IPY_MODEL_70973fd805f74cfaa6ad8a52772c6107"
          }
        },
        "05f7ed81ad7346758a7b71eaef5dbe52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719eafce4b114edfba31c2afce7735f4",
            "placeholder": "​",
            "style": "IPY_MODEL_aff8ae144d6d416db8d25d4d3a1b3d1a",
            "value": "Downloading: 100%"
          }
        },
        "a5916dc7e87844b2b582cb790638db55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f74cc01c4af44b7a52b51a6073f09e9",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3084b228e99343b3818c9e622c054735",
            "value": 213450
          }
        },
        "dc56be297cad499eaca6ef0c56aff181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d951523fca94a62ad8e006a5bd88ad9",
            "placeholder": "​",
            "style": "IPY_MODEL_348c45ecc3c243079ce4b831af106bff",
            "value": " 213k/213k [00:00&lt;00:00, 260kB/s]"
          }
        },
        "70973fd805f74cfaa6ad8a52772c6107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719eafce4b114edfba31c2afce7735f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff8ae144d6d416db8d25d4d3a1b3d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f74cc01c4af44b7a52b51a6073f09e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3084b228e99343b3818c9e622c054735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d951523fca94a62ad8e006a5bd88ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348c45ecc3c243079ce4b831af106bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a3259d66caf492c86a715206b340cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_275f1f9b72194e159a256661f639be6a",
              "IPY_MODEL_c6ed2c5e9fa2468c8c6185c86f03b929",
              "IPY_MODEL_e6982dfcfac7495ab544b2e6bce4328b"
            ],
            "layout": "IPY_MODEL_65bb4b7fc411449eb3ac379839407783"
          }
        },
        "275f1f9b72194e159a256661f639be6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96dc9eaf44a34e7f97f878df78b68d9b",
            "placeholder": "​",
            "style": "IPY_MODEL_bc1bf6867c8b4323a0d88a8043c73821",
            "value": "Downloading: 100%"
          }
        },
        "c6ed2c5e9fa2468c8c6185c86f03b929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a39ceecccbdf4587a4859b0b389f4bd3",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c9474cd6d3d44d6868dd3eaebee3514",
            "value": 29
          }
        },
        "e6982dfcfac7495ab544b2e6bce4328b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67f1b3fbc054149b22f196f0e6ae950",
            "placeholder": "​",
            "style": "IPY_MODEL_27008ebd869441898525426d7527f03c",
            "value": " 29.0/29.0 [00:00&lt;00:00, 895B/s]"
          }
        },
        "65bb4b7fc411449eb3ac379839407783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96dc9eaf44a34e7f97f878df78b68d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc1bf6867c8b4323a0d88a8043c73821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a39ceecccbdf4587a4859b0b389f4bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c9474cd6d3d44d6868dd3eaebee3514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d67f1b3fbc054149b22f196f0e6ae950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27008ebd869441898525426d7527f03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef3f099810414e58a2b4c497fe6b7c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dce436c2729449f844009a154650eb8",
              "IPY_MODEL_c5a9f763762e45adab214a3d3f3b05b6",
              "IPY_MODEL_dd1237aef3724779a7fd8805e9db6590"
            ],
            "layout": "IPY_MODEL_824c1bfa13b1458b90b3d2ac133e1ca8"
          }
        },
        "2dce436c2729449f844009a154650eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fe6a0dbc1eb4489bab2553f05466746",
            "placeholder": "​",
            "style": "IPY_MODEL_27c11831838b4f6cabcc6b423bcb74ba",
            "value": "Downloading: 100%"
          }
        },
        "c5a9f763762e45adab214a3d3f3b05b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bbe100ccd124f9eb7ae47a57e382f70",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f522cfe4483e48c2b0bfaa1ff3bea689",
            "value": 570
          }
        },
        "dd1237aef3724779a7fd8805e9db6590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfe319f5ab0d4da695b4ce63507a306d",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1049c0e682498c8397589ea10a5673",
            "value": " 570/570 [00:00&lt;00:00, 18.3kB/s]"
          }
        },
        "824c1bfa13b1458b90b3d2ac133e1ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe6a0dbc1eb4489bab2553f05466746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c11831838b4f6cabcc6b423bcb74ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bbe100ccd124f9eb7ae47a57e382f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f522cfe4483e48c2b0bfaa1ff3bea689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfe319f5ab0d4da695b4ce63507a306d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1049c0e682498c8397589ea10a5673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8f84d3aba3d4f5cb235f36184f36432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4143fcc31a5843dea68389b0efedbea5",
              "IPY_MODEL_4a124021663542c3849ed697f0aa1e22",
              "IPY_MODEL_848a0546dc0548bc90cbcb1183c42f16"
            ],
            "layout": "IPY_MODEL_aba48648c27f446c85ef8486fbe1be71"
          }
        },
        "4143fcc31a5843dea68389b0efedbea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b88eab098b2e4a278c2d52ab5a483908",
            "placeholder": "​",
            "style": "IPY_MODEL_9427bea9aa21430da6e16dc2b53cea59",
            "value": "Downloading: 100%"
          }
        },
        "4a124021663542c3849ed697f0aa1e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030f0af36d814989994f80535ddfc928",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_418b3523c1f242ce882fde60a5fb4e81",
            "value": 435779157
          }
        },
        "848a0546dc0548bc90cbcb1183c42f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4f2585016794ab4abb7a28b1f7e0024",
            "placeholder": "​",
            "style": "IPY_MODEL_0a520f89d7544ccab5cf3b3be417bdd3",
            "value": " 436M/436M [00:07&lt;00:00, 59.1MB/s]"
          }
        },
        "aba48648c27f446c85ef8486fbe1be71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88eab098b2e4a278c2d52ab5a483908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9427bea9aa21430da6e16dc2b53cea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "030f0af36d814989994f80535ddfc928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418b3523c1f242ce882fde60a5fb4e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4f2585016794ab4abb7a28b1f7e0024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a520f89d7544ccab5cf3b3be417bdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4a32ma6AA5L",
        "outputId": "1e25da1a-10b1-4451-dff7-00a455302d8d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 63.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recordclass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUTeB07nAIwv",
        "outputId": "44f55912-d729-4f99-b497-e942b5126516"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting recordclass\n",
            "  Downloading recordclass-0.18.0.1.tar.gz (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 32.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: recordclass\n",
            "  Building wheel for recordclass (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for recordclass: filename=recordclass-0.18.0.1-cp37-cp37m-linux_x86_64.whl size=294327 sha256=fe98efd03e9ffc1940be7a267aad2a5ccb642dd4d7df99ac70c4083772b95ed0\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/6e/8b/d0142e83a9a5254fdc35c25b22db063efd5dec419a4c319462\n",
            "Successfully built recordclass\n",
            "Installing collected packages: recordclass\n",
            "Successfully installed recordclass-0.18.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2Bi2_vZl-7w4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import datetime\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "#from pytorch_transformers import BertTokenizer, BertModel, AdamW\n",
        "from transformers import BertTokenizer, BertModel, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from recordclass import recordclass\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle"
      ],
      "metadata": {
        "id": "VRiYJ9gT_yTH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_print(*msg):\n",
        "    for i in range(0, len(msg)):\n",
        "        if i == len(msg) - 1:\n",
        "            print(msg[i])\n",
        "            logger.write(str(msg[i]) + '\\n')\n",
        "        else:\n",
        "            print(msg[i], ' ', end='')\n",
        "            logger.write(str(msg[i]))\n",
        "\n",
        "def get_data(src_lines, trg_lines, pos_lines,  dep_lines, datatype):\n",
        "    samples = []\n",
        "    uid = 1\n",
        "    #print(len(src_lines))\n",
        "    for i in range(0, len(src_lines)):#for each line\n",
        "        src_line = src_lines[i].strip()\n",
        "        #print(src_line)\n",
        "        trg_line = trg_lines[i].strip()\n",
        "        pos_line = pos_lines[i].strip()\n",
        "        #ent_line = ent_lines[i].strip()\n",
        "        dep_line = dep_lines[i].strip()\n",
        "\n",
        "        src_words = src_line.split()\n",
        "        word_pos_tags = pos_line.split()####\n",
        "        #word_ent_tags = ent_line.split()####\n",
        "        word_dep_tags = dep_line.split()\n",
        "\n",
        "        trg_rels = []#holds relations present in a sentence\n",
        "        trg_events=[]#holds events present in a sentence\n",
        "        trg_args=[]#holds arguments present in a sentence\n",
        "        trg_pointers = []#holds tuples containg records per relation\n",
        "        parts = trg_line.split('|')\n",
        "        '''\n",
        "        if datatype == 1:\n",
        "            random.shuffle(parts)\n",
        "        '''\n",
        "\n",
        "        #adj_data = json.loads(adj_lines[i])#skip\n",
        "        #adj_mat = get_adj_mat(len(src_words), adj_data['adj_mat'])#skip\n",
        "\n",
        "        tuples_in=[]\n",
        "        for part in parts:\n",
        "            elements = part.strip().split()\n",
        "            if(len(elements)==0):\n",
        "              continue\n",
        "            #print(elements)\n",
        "            tuples_in.append((int(elements[0]), int(elements[1]), eventnameToIdx[elements[2]], int(elements[3]), int(elements[4]), argnameToIdx[elements[5]], relnameToIdx[elements[6]]))\n",
        "\n",
        "        if datatype ==1:\n",
        "            tuples_in = sorted(tuples_in, key = lambda element: (element[0], element[3]))\n",
        "        for elements in tuples_in:\n",
        "            #elements = part.strip().split()\n",
        "            #print(elements)\n",
        "            trg_rels.append(elements[6])#relation index (corresponding to the relation_name from relation_vocab)\n",
        "            trg_events.append(elements[2])#event index\n",
        "            trg_args.append(elements[5])#arg index\n",
        "            trg_pointers.append((int(elements[0]), int(elements[1]), int(elements[3]), int(elements[4])))#all the records like event-start_index, end_index, entity- start_index, end_index\n",
        "\n",
        "        if datatype == 1 and (len(src_words) > max_src_len or len(trg_rels) > max_trg_len):#if cross max_sentence_length or max_trg_length(max no of relation tuples present in the sentence)\n",
        "            #print(src_line)\n",
        "            #print(trg_line)\n",
        "            continue\n",
        "\n",
        "        sample = Sample(Id=uid, SrcLen=len(src_words), SrcWords=src_words, PosTags=word_pos_tags,DepTags=word_dep_tags, TrgLen=len(trg_rels), TrgRels=trg_rels,\n",
        "                        TrgPointers=trg_pointers, eventTypes=trg_events, argTypes=trg_args)#recordclass(\"Sample\", \"Id SrcLen SrcWords TrgLen TrgRels eventTypes argTypes TrgPointers\")\n",
        "        samples.append(sample)\n",
        "        uid += 1\n",
        "    return samples\n"
      ],
      "metadata": {
        "id": "SW40bb6CAGjP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(src_file, trg_file, pos_file, dep_file, datatype):\n",
        "    reader = open(src_file)\n",
        "    src_lines = reader.readlines()\n",
        "    reader.close()\n",
        "\n",
        "    reader = open(trg_file)\n",
        "    trg_lines = reader.readlines()\n",
        "    reader.close()\n",
        "\n",
        "    reader = open(pos_file)\n",
        "    pos_lines = reader.readlines()\n",
        "    reader.close()\n",
        "\n",
        "    # reader = open(ent_file)\n",
        "    # ent_lines = reader.readlines()\n",
        "    # reader.close()\n",
        "\n",
        "    reader = open(dep_file)\n",
        "    dep_lines = reader.readlines()\n",
        "    reader.close()\n",
        "    \n",
        "    # l = 1000\n",
        "    # src_lines = src_lines[0:min(l, len(src_lines))]\n",
        "    # trg_lines = trg_lines[0:min(l, len(trg_lines))]\n",
        "    # adj_lines = adj_lines[0:min(l, len(adj_lines))]\n",
        "\n",
        "    data = get_data(src_lines, trg_lines, pos_lines, dep_lines, datatype)#call get_data()\n",
        "    return data#list of records, records are of type Sample\n"
      ],
      "metadata": {
        "id": "O0lDFaySAXLl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relations(file_name):\n",
        "    nameToIdx = OrderedDict()#dictionary{key=name. value=idx}\n",
        "    idxToName = OrderedDict()#dictionary{key=idx, value=name}\n",
        "    reader = open(file_name)\n",
        "    lines = reader.readlines()\n",
        "    reader.close()\n",
        "    nameToIdx['<PAD>'] = 0\n",
        "    idxToName[0] = '<PAD>'\n",
        "    # nameToIdx['<SOS>'] = 1\n",
        "    # idxToName[1] = '<SOS>'\n",
        "    #nameToIdx['None'] = 1\n",
        "    #idxToName[1] = 'None'\n",
        "    idx = 1\n",
        "    for line in lines:\n",
        "        nameToIdx[line.strip()] = idx\n",
        "        idxToName[idx] = line.strip()\n",
        "        idx += 1\n",
        "    return nameToIdx, idxToName\n",
        "\n",
        "def get_events(file_name):\n",
        "    nameToIdx = OrderedDict()#dictionary{key=name. value=idx}\n",
        "    idxToName = OrderedDict()#dictionary{key=idx, value=name}\n",
        "    reader = open(file_name)\n",
        "    lines = reader.readlines()\n",
        "    reader.close()\n",
        "    nameToIdx['<PAD>'] = 0\n",
        "    idxToName[0] = '<PAD>'\n",
        "    # nameToIdx['<SOS>'] = 1\n",
        "    # idxToName[1] = '<SOS>'\n",
        "    #nameToIdx['None'] = 1\n",
        "    #idxToName[1] = 'None'\n",
        "    idx = 1\n",
        "    for line in lines:\n",
        "        nameToIdx[line.strip()] = idx\n",
        "        idxToName[idx] = line.strip()\n",
        "        idx += 1\n",
        "    return nameToIdx, idxToName\n",
        "\n",
        "def get_arguments(file_name):\n",
        "    nameToIdx = OrderedDict()#dictionary{key=name. value=idx}\n",
        "    idxToName = OrderedDict()#dictionary{key=idx, value=name}\n",
        "    reader = open(file_name)\n",
        "    lines = reader.readlines()\n",
        "    reader.close()\n",
        "    nameToIdx['<PAD>'] = 0\n",
        "    idxToName[0] = '<PAD>'\n",
        "    # nameToIdx['<SOS>'] = 1\n",
        "    # idxToName[1] = '<SOS>'\n",
        "    #nameToIdx['None'] = 1\n",
        "    #idxToName[1] = 'None'\n",
        "    idx = 1\n",
        "    for line in lines:\n",
        "        nameToIdx[line.strip()] = idx\n",
        "        idxToName[idx] = line.strip()\n",
        "        idx += 1\n",
        "    return nameToIdx, idxToName\n"
      ],
      "metadata": {
        "id": "7jmMr_XSAcJK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_full_match(triplet, triplets):\n",
        "    for t in triplets:\n",
        "        if t[0] == triplet[0] and t[1] == triplet[1] and t[2] == triplet[2] and t[4] == triplet[4]:\n",
        "            return True\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "ko3msR5wAg6X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gt_triples(src_words, rels, pointers, event_list, arg_list):\n",
        "    touples = []\n",
        "    i = 0\n",
        "    for r in rels:\n",
        "        arg1 = ' '.join(src_words[pointers[i][0]:pointers[i][1] + 1])\n",
        "        arg2 = ' '.join(src_words[pointers[i][2]:pointers[i][3] + 1])\n",
        "        touplet = (arg1.strip(), eventIdxToName[event_list[i]], arg2.strip(), argIdxToName[arg_list[i]], relIdxToName[r])\n",
        "        if not is_full_match(touplet, touples):\n",
        "            touples.append(touplet)\n",
        "        i += 1\n",
        "    '''\n",
        "    for e in event_list:\n",
        "        arg1 = ' '.join(src_words[pointers[i][0]:pointers[i][1] + 1])\n",
        "        arg2 = ' '.join(src_words[pointers[i][2]:pointers[i][3] + 1])\n",
        "        touplet = (arg1.strip(), eventIdxToName[e], arg2.strip(), argIdxToName[arg_list[i]], relIdxToName[rels[i]])\n",
        "        if not is_full_match(touplet, touples):\n",
        "            touples.append(touplet)\n",
        "        i += 1\n",
        "    '''\n",
        "    return touples\n"
      ],
      "metadata": {
        "id": "3Zp8Tn5cAlMV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer_pointers(arg1start_preds, arg1end_preds, arg2start_preds, arg2end_preds, sent_len):\n",
        "    arg1_prob = -1.0\n",
        "    arg1start = -1\n",
        "    arg1end = -1\n",
        "    max_ent_len = 38#5\n",
        "    max_trig_len = 7#\n",
        "    for i in range(0, sent_len):\n",
        "        for j in range(i, min(sent_len, i + max_trig_len)):#\n",
        "            if arg1start_preds[i] * arg1end_preds[j] > arg1_prob:\n",
        "                arg1_prob = arg1start_preds[i] * arg1end_preds[j]\n",
        "                arg1start = i\n",
        "                arg1end = j\n",
        "\n",
        "    arg2_prob = -1.0\n",
        "    arg2start = -1\n",
        "    arg2end = -1\n",
        "    for i in range(0, arg1start):\n",
        "        for j in range(i, min(arg1start, i + max_ent_len)):#\n",
        "            if arg2start_preds[i] * arg2end_preds[j] > arg2_prob:\n",
        "                arg2_prob = arg2start_preds[i] * arg2end_preds[j]\n",
        "                arg2start = i\n",
        "                arg2end = j\n",
        "    for i in range(arg1end + 1, sent_len):\n",
        "        for j in range(i, min(sent_len, i + max_ent_len)):#\n",
        "            if arg2start_preds[i] * arg2end_preds[j] > arg2_prob:\n",
        "                arg2_prob = arg2start_preds[i] * arg2end_preds[j]\n",
        "                arg2start = i\n",
        "                arg2end = j\n",
        "\n",
        "    arg2_prob1 = -1.0\n",
        "    arg2start1 = -1\n",
        "    arg2end1 = -1\n",
        "    for i in range(0, sent_len):\n",
        "        for j in range(i, min(sent_len, i + max_ent_len)):#\n",
        "            if arg2start_preds[i] * arg2end_preds[j] > arg2_prob1:\n",
        "                arg2_prob1 = arg2start_preds[i] * arg2end_preds[j]\n",
        "                arg2start1 = i\n",
        "                arg2end1 = j\n",
        "\n",
        "    arg1_prob1 = -1.0\n",
        "    arg1start1 = -1\n",
        "    arg1end1 = -1\n",
        "    for i in range(0, arg2start1):\n",
        "        for j in range(i, min(arg2start1, i + max_trig_len)):#\n",
        "            if arg1start_preds[i] * arg1end_preds[j] > arg1_prob1:\n",
        "                arg1_prob1 = arg1start_preds[i] * arg1end_preds[j]\n",
        "                arg1start1 = i\n",
        "                arg1end1 = j\n",
        "    for i in range(arg2end1 + 1, sent_len):\n",
        "        for j in range(i, min(sent_len, i + max_trig_len)):\n",
        "            if arg1start_preds[i] * arg1end_preds[j] > arg1_prob1:\n",
        "                arg1_prob1 = arg1start_preds[i] * arg1end_preds[j]\n",
        "                arg1start1 = i\n",
        "                arg1end1 = j\n",
        "    if arg1_prob * arg2_prob > arg1_prob1 * arg2_prob1:\n",
        "        return arg1start, arg1end, arg2start, arg2end\n",
        "    else:\n",
        "        return arg1start1, arg1end1, arg2start1, arg2end1\n"
      ],
      "metadata": {
        "id": "FVTEc_53ApRm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_triples(rel, arg1s, arg1e, arg2s, arg2e, eTypes, aTypes, src_words):\n",
        "    touples = []\n",
        "    all_touples = []\n",
        "\n",
        "    for i in range(0, len(rel)):\n",
        "\n",
        "        s1, e1, s2, e2 = get_answer_pointers(arg1s[i], arg1e[i], arg2s[i], arg2e[i], len(src_words))\n",
        "        if s1 == 0 or e1 == 0 :\n",
        "            break\n",
        "        r = np.argmax(rel[i][1:]) + 1\n",
        "        ev = np.argmax(eTypes[i][1:]) + 1#event type can not be <pad> or <None>\n",
        "        at = np.argmax(aTypes[i][1:]) + 1\n",
        "\n",
        "\n",
        "        arg1 = ' '.join(src_words[s1: e1 + 1])\n",
        "        arg2 = ' '.join(src_words[s2: e2 + 1])\n",
        "        arg1 = arg1.strip()\n",
        "        arg2 = arg2.strip()\n",
        "        if arg1 == arg2:\n",
        "            continue\n",
        "        touplet = (arg1, eventIdxToName[ev], arg2, argIdxToName[at], relIdxToName[r])\n",
        "        if (touplet[0], touplet[1], touplet[2]) in [(t[0], t[1],t[2]) for t in touples]:#same (trigger, argument) pair can not have two different role\n",
        "        \tcontinue\n",
        "\n",
        "        all_touples.append(touplet)\n",
        "\n",
        "        if not is_full_match(touplet, touples):\n",
        "            touples.append(touplet)\n",
        "    '''\n",
        "\n",
        "    for i in range(0, len(eTypes)):\n",
        "        r = np.argmax(rel[i][1:]) + 1\n",
        "        if r == relnameToIdx['None']:\n",
        "            break\n",
        "        s1, e1, s2, e2 = get_answer_pointers(arg1s[i], arg1e[i], arg2s[i], arg2e[i], len(src_words))\n",
        "        arg1 = ' '.join(src_words[s1: e1 + 1])\n",
        "        arg2 = ' '.join(src_words[s2: e2 + 1])\n",
        "        arg1 = arg1.strip()\n",
        "        arg2 = arg2.strip()\n",
        "        if arg1 == arg2:\n",
        "            continue\n",
        "        triplet = (arg1, arg2, relIdxToName[r])\n",
        "        all_triples.append(triplet)\n",
        "        if not is_full_match(triplet, triples):\n",
        "            triples.append(triplet)\n",
        "    '''\n",
        "    return touples, all_touples\n"
      ],
      "metadata": {
        "id": "0McCJvSrAxM4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_F1(data, preds):\n",
        "    gt_pos = 0\n",
        "    pred_pos = 0\n",
        "    total_pred_pos = 0\n",
        "    correct_pos = 0\n",
        "    for i in range(0, len(data)):\n",
        "        ##[2,45,67,10],[2,5,13,7],[(1,2,6,7),(7,8,10,10),..],[23,33,1,8]\n",
        "        gt_triples = get_gt_triples(data[i].SrcWords, data[i].TrgRels, data[i].TrgPointers, data[i].eventTypes, data[i].argTypes)\n",
        "\n",
        "        pred_triples, all_pred_triples = get_pred_triples(preds[0][i], preds[1][i], preds[2][i], preds[3][i],\n",
        "                                                          preds[4][i], preds[5][i], preds[6][i], data[i].SrcWords)\n",
        "        total_pred_pos += len(all_pred_triples)\n",
        "        gt_pos += len(gt_triples)\n",
        "        pred_pos += len(pred_triples)\n",
        "        for gt_triple in gt_triples:\n",
        "            if is_full_match(gt_triple, pred_triples):\n",
        "                correct_pos += 1\n",
        "    print(total_pred_pos)\n",
        "    return pred_pos, gt_pos, correct_pos\n",
        "\n",
        "def write_test_res(data, actual_sent, actual_data, preds, outfile):\n",
        "    writer = open(outfile, 'w')\n",
        "    for i in range(0, len(data)):\n",
        "        writer.write('Sentence= ' + actual_sent[i])\n",
        "        writer.write('\\n')\n",
        "        writer.write('Actual= '+ actual_data[i])\n",
        "        writer.write('\\n')\n",
        "        pred_triples, _ = get_pred_triples(preds[0][i], preds[1][i], preds[2][i], preds[3][i], preds[4][i], preds[5][i], preds[6][i], data[i].SrcWords)\n",
        "        pred_triples_str = []\n",
        "        for pt in pred_triples:\n",
        "            pred_triples_str.append(pt[0] + ' ; ' + pt[1] + ' ; ' + pt[2] + ' ; ' + pt[3] + ' ; ' + pt[4])\n",
        "        writer.write('predicted:  ')\n",
        "        writer.write(' | '.join(pred_triples_str) + '\\n\\n\\n')\n",
        "    writer.close()\n",
        "\n",
        "def load_word_embedding(embed_file, vocab):\n",
        "    '''\n",
        "    vocab: all the uniq words present in the doc\n",
        "    embed_file: pretrained word embedding path\n",
        "    '''\n",
        "    #print('vocab length:', len(vocab))\n",
        "    custom_print('vocab length:', len(vocab))\n",
        "    embed_vocab = OrderedDict()#dictionar containing all the words and word_index\n",
        "    embed_matrix = list()\n",
        "\n",
        "    embed_vocab['<PAD>'] = 0\n",
        "    embed_matrix.append(np.zeros(word_embed_dim, dtype=np.float32))\n",
        "\n",
        "    embed_vocab['<UNK>'] = 1\n",
        "    embed_matrix.append(np.random.uniform(-0.25, 0.25, word_embed_dim))\n",
        "\n",
        "    word_idx = 2\n",
        "    with open(embed_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.split()\n",
        "            if len(parts) < word_embed_dim + 1:\n",
        "                continue\n",
        "            word = parts[0]\n",
        "            if word in vocab and vocab[word] >= word_min_freq:\n",
        "                vec = [np.float32(val) for val in parts[1:]]\n",
        "                embed_matrix.append(vec)\n",
        "                embed_vocab[word] = word_idx\n",
        "                word_idx += 1\n",
        "\n",
        "    for word in vocab:\n",
        "        if word not in embed_vocab and vocab[word] >= word_min_freq:\n",
        "            embed_matrix.append(np.random.uniform(-0.25, 0.25, word_embed_dim))\n",
        "            embed_vocab[word] = word_idx\n",
        "            word_idx += 1\n",
        "\n",
        "    #print('embed dictionary length:', len(embed_vocab))\n",
        "    custom_print('embed dictionary length:', len(embed_vocab))\n",
        "    return embed_vocab, np.array(embed_matrix, dtype=np.float32)\n",
        "\n",
        "def build_vocab(tr_data, dv_data, ts_data, save_vocab, embedding_file):\n",
        "    vocab = OrderedDict()\n",
        "    char_v = OrderedDict()\n",
        "    char_v['<PAD>'] = 0\n",
        "    char_v['<UNK>'] = 1\n",
        "    char_idx = 2\n",
        "    for d in tr_data:\n",
        "        for word in d.SrcWords:\n",
        "            if word not in vocab:\n",
        "                vocab[word] = 1\n",
        "            else:\n",
        "                vocab[word] += 1\n",
        "\n",
        "            for c in word:\n",
        "                if c not in char_v:\n",
        "                    char_v[c] = char_idx\n",
        "                    char_idx += 1\n",
        "\n",
        "    for d in dv_data + ts_data:\n",
        "        for word in d.SrcWords:\n",
        "            if word not in vocab:\n",
        "                vocab[word] = 0\n",
        "\n",
        "            for c in word:\n",
        "                if c not in char_v:\n",
        "                    char_v[c] = char_idx\n",
        "                    char_idx += 1\n",
        "\n",
        "    word_v, embed_matrix = load_word_embedding(embedding_file, vocab)\n",
        "    output = open(save_vocab, 'wb')\n",
        "    pickle.dump([word_v, char_v, pos_vocab, dep_vocab], output)\n",
        "    output.close()\n",
        "    return word_v, char_v, embed_matrix\n",
        "\n",
        "def build_tags(file1, file2, file3):\n",
        "    lines = open(file1).readlines() + open(file2).readlines() + open(file3).readlines()\n",
        "    pos_vocab = OrderedDict()\n",
        "    pos_vocab['<PAD>'] = 0\n",
        "    pos_vocab['<UNK>'] = 1\n",
        "    k = 2\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        tags = line.split(' ')\n",
        "        for tag in tags:\n",
        "            if tag not in pos_vocab:\n",
        "                pos_vocab[tag] = k\n",
        "                k += 1\n",
        "    return pos_vocab\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    with open(vocab_file, 'rb') as f:\n",
        "        embed_vocab, char_vocab, pos_vocab, dep_vocab = pickle.load(f)\n",
        "    return embed_vocab, char_vocab, pos_vocab, dep_vocab\n",
        "\n",
        "def get_max_len(sample_batch):\n",
        "    src_max_len = len(sample_batch[0].SrcWords)\n",
        "    for idx in range(1, len(sample_batch)):\n",
        "        if len(sample_batch[idx].SrcWords) > src_max_len:\n",
        "            src_max_len = len(sample_batch[idx].SrcWords)\n",
        "\n",
        "    trg_max_len = len(sample_batch[0].TrgRels)\n",
        "    for idx in range(1, len(sample_batch)):\n",
        "        if len(sample_batch[idx].TrgRels) > trg_max_len:\n",
        "            trg_max_len = len(sample_batch[idx].TrgRels)\n",
        "\n",
        "    return src_max_len, trg_max_len\n",
        "\n",
        "def get_words_index_seq(words, max_len):\n",
        "    toks = ['[CLS]'] + [wd for wd in words] + ['[SEP]'] + ['[PAD]' for i in range(max_len-len(words))]\n",
        "    bert_ids = bert_tokenizer.convert_tokens_to_ids(toks)\n",
        "    bert_mask = [1 for idx in range(len(words) + 2)] + [0 for idx in range(max_len - len(words))]\n",
        "    return bert_ids, bert_mask"
      ],
      "metadata": {
        "id": "YRZcy_2tA0o8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_tag_index_seq(pos_seq, max_len):\n",
        "    seq = list()\n",
        "    for t in pos_seq:\n",
        "        if t in pos_vocab:\n",
        "            seq.append(pos_vocab[t])\n",
        "        else:\n",
        "            seq.append(pos_vocab['<UNK>'])\n",
        "    pad_len = max_len - len(seq)\n",
        "    for i in range(0, pad_len):\n",
        "        seq.append(pos_vocab['<PAD>'])\n",
        "    return seq\n",
        "\n",
        "\n",
        "# def get_ent_tag_index_seq(ent_seq, max_len):\n",
        "#     seq = list()\n",
        "#     for t in ent_seq:\n",
        "#         if t in ent_vocab:\n",
        "#             seq.append(ent_vocab[t])\n",
        "#         else:\n",
        "#             seq.append(ent_vocab['<UNK>'])\n",
        "#     pad_len = max_len - len(seq)\n",
        "#     for i in range(0, pad_len):\n",
        "#         seq.append(ent_vocab['<PAD>'])\n",
        "#     return seq\n",
        "\n",
        "\n",
        "def get_dep_tag_index_seq(dep_seq, max_len):\n",
        "    seq = list()\n",
        "    for t in dep_seq:\n",
        "        if t in dep_vocab:\n",
        "            seq.append(dep_vocab[t])\n",
        "        else:\n",
        "            seq.append(dep_vocab['<UNK>'])\n",
        "    pad_len = max_len - len(seq)\n",
        "    for i in range(0, pad_len):\n",
        "        seq.append(dep_vocab['<PAD>'])\n",
        "    return seq\n"
      ],
      "metadata": {
        "id": "RPxEZ9GkA6xO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_padded_mask(cur_len, max_len):\n",
        "    mask_seq = list()\n",
        "    for i in range(0, cur_len):\n",
        "        mask_seq.append(0)\n",
        "    pad_len = max_len - cur_len\n",
        "    for i in range(0, pad_len):\n",
        "        mask_seq.append(1)\n",
        "    return mask_seq\n"
      ],
      "metadata": {
        "id": "fFyin2eSA-Xn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_char_seq(words, max_len):\n",
        "    char_seq = list()\n",
        "    for i in range(0, conv_filter_size - 1):\n",
        "        char_seq.append(char_vocab['<PAD>'])\n",
        "    for word in words:\n",
        "        for c in word[0:min(len(word), max_word_len)]:\n",
        "            if c in char_vocab:\n",
        "                char_seq.append(char_vocab[c])\n",
        "            else:\n",
        "                char_seq.append(char_vocab['<UNK>'])\n",
        "        pad_len = max_word_len - len(word)\n",
        "        for i in range(0, pad_len):\n",
        "            char_seq.append(char_vocab['<PAD>'])\n",
        "        for i in range(0, conv_filter_size - 1):\n",
        "            char_seq.append(char_vocab['<PAD>'])\n",
        "\n",
        "    pad_len = max_len - len(words)\n",
        "    for i in range(0, pad_len):\n",
        "        for i in range(0, max_word_len + conv_filter_size - 1):\n",
        "            char_seq.append(char_vocab['<PAD>'])\n",
        "    return char_seq\n",
        "\n"
      ],
      "metadata": {
        "id": "PW1bVxmQBAxZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[1,7,3,10,-1,-1,-1,...]\n",
        "def get_padded_pointers_trig(pointers, pidx, max_len):\n",
        "    idx_list = []\n",
        "    for p in pointers:\n",
        "        idx_list.append(p[pidx])\n",
        "    idx_list.append(0)\n",
        "    pad_len = max_len - len(pointers)\n",
        "    for i in range(0, pad_len):\n",
        "        idx_list.append(-1)\n",
        "    return idx_list\n",
        "\n",
        "\n",
        "\n",
        "#[1,7,3,10,-1,-1,-1,...]\n",
        "def get_padded_pointers_arg(pointers, pidx, max_len):\n",
        "    idx_list = []\n",
        "    for p in pointers:\n",
        "        idx_list.append(p[pidx])\n",
        "    idx_list.append(1)\n",
        "    pad_len = max_len - len(pointers)\n",
        "    for i in range(0, pad_len):\n",
        "        idx_list.append(-1)\n",
        "    return idx_list\n",
        "\n"
      ],
      "metadata": {
        "id": "71rnoq8JBDZ2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[1,2,3,4,0,0,0,...]\n",
        "def get_positional_index(sent_len, max_len):\n",
        "    index_seq = [min(i + 1, max_positional_idx - 1) for i in range(sent_len)]\n",
        "    index_seq += [0 for i in range(max_len - sent_len)]\n",
        "    return index_seq"
      ],
      "metadata": {
        "id": "ElLG4-OCBGtq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
        "def get_padded_relations(rels, max_len):\n",
        "    rel_list = []\n",
        "    for r in rels:\n",
        "        rel_list.append(r)\n",
        "    rel_list.append(relnameToIdx['NA'])\n",
        "    pad_len = max_len + 1 - len(rel_list)\n",
        "    for i in range(0, pad_len):\n",
        "        rel_list.append(relnameToIdx['<PAD>'])\n",
        "    return rel_list"
      ],
      "metadata": {
        "id": "e1vy5JumBJTB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
        "def get_padded_events(events, max_len):\n",
        "    event_list = []\n",
        "    for r in events:\n",
        "        event_list.append(r)\n",
        "    #event_list.append(eventnameToIdx['None'])\n",
        "    pad_len = max_len + 1 - len(event_list)\n",
        "    for i in range(0, pad_len):\n",
        "        event_list.append(eventnameToIdx['<PAD>'])\n",
        "    return event_list\n",
        "\n"
      ],
      "metadata": {
        "id": "oRPCi6NTBMJS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
        "def get_padded_args(args, max_len):\n",
        "    arg_list = []\n",
        "    for r in args:\n",
        "        arg_list.append(r)\n",
        "    arg_list.append(argnameToIdx['NA'])\n",
        "    pad_len = max_len + 1 - len(arg_list)\n",
        "    for i in range(0, pad_len):\n",
        "        arg_list.append(argnameToIdx['<PAD>'])\n",
        "    return arg_list\n",
        "\n"
      ],
      "metadata": {
        "id": "nNJKRIIBBOSm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
        "def get_relation_index_seq(rel_ids, max_len):\n",
        "    seq = list()\n",
        "    # seq.append(relnameToIdx['<SOS>'])\n",
        "    for r in rel_ids:\n",
        "        seq.append(r)\n",
        "    seq.append(relnameToIdx['NA'])\n",
        "    pad_len = max_len + 1 - len(seq)\n",
        "    for i in range(0, pad_len):\n",
        "        seq.append(relnameToIdx['<PAD>'])\n",
        "    return seq\n"
      ],
      "metadata": {
        "id": "-fQm4-XjBQ_4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entity_masks(pointers, src_max, trg_max):\n",
        "    arg1_masks = []#\n",
        "    arg2_masks = []#\n",
        "    for p in pointers:#for each record in a sentence\n",
        "        arg1_mask = [1 for i in range(src_max)]#list of size max_src_len [1, 1, 1, 1,...]\n",
        "        arg1_mask[p[0]] = 0#set the value of word_pos_index of the first word of entity_1=0 [1, 1, 1, 0, 1, 1,...]\n",
        "        arg1_mask[p[1]] = 0#set the value of word_pos_index of the last word of entity_1=0 [1, 1, 1, 0, 1, 1, 0, 1, 1,...]\n",
        "\n",
        "        arg2_mask = [1 for i in range(src_max)]#list of size max_src_len [1, 1, 1,...]\n",
        "        arg2_mask[p[2]] = 0#set the value of word_pos_index of the first word of entity_1=0\n",
        "        arg2_mask[p[3]] = 0#set the value of word_pos_index of the last word of entity_2=0\n",
        "\n",
        "        arg1_masks.append(arg1_mask)\n",
        "        arg2_masks.append(arg2_mask)\n",
        "\n",
        "    pad_len = trg_max + 1 -len(pointers)\n",
        "    for i in range(0, pad_len):\n",
        "        arg1_mask = [1 for i in range(src_max)]\n",
        "        arg2_mask = [1 for i in range(src_max)]\n",
        "        arg1_masks.append(arg1_mask)\n",
        "        arg2_masks.append(arg2_mask)\n",
        "    return arg1_masks, arg2_masks #list of length max_trg_len where each item is list of size max_src_len. Each item of that list is mask where all but start and end index of entity_1 and entity_2 set to 1 respectively.\n"
      ],
      "metadata": {
        "id": "n-1XvkCmBTvB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_data(cur_samples, is_training=False):\n",
        "    \"\"\"\n",
        "    Returns the training samples and labels as numpy array\n",
        "    \"\"\"\n",
        "    batch_src_max_len, batch_trg_max_len = get_max_len(cur_samples)#call get_max_len(): find the max length of src and target per batch\n",
        "    batch_trg_max_len += 1#may be EOS relation\n",
        "    #print('max_src_len_batch={}'.format(batch_src_max_len))\n",
        "    #print('max_trg_len_batch={}'.format(batch_trg_max_len))\n",
        "    src_words_list = list()#each element is a list of word indices present in a sentence\n",
        "    bert_mask_list = list()\n",
        "    src_words_mask_list = list()#each element is a list of mask value, 0 if actual word and 1 if padded word\n",
        "    src_char_seq = list()#each element is a charater idex sequence per sentence\n",
        "    decoder_input_list = list()\n",
        "    #adj_lst = []\n",
        "    positional_index_list = []#each element is a sequence of positional index of the words in a sentence\n",
        "    src_pos_tag_seq = list()#pos tag\n",
        "    src_ent_tag_seq = list()#ent tag\n",
        "    src_dep_tag_seq = list()#dep tag\n",
        "    rel_seq = list()\n",
        "    event_seq=list()#******\n",
        "    arg_seq=list()#********\n",
        "    trigger_start_seq = list()\n",
        "    trigger_end_seq = list()\n",
        "    entity_start_seq = list()\n",
        "    entity_end_seq = list()\n",
        "    trigger_mask_seq = []\n",
        "    entity_mask_seq = []\n",
        "    '''all commmnets in the following are about the 'items' appended to that respective lists'''\n",
        "    for sample in cur_samples:\n",
        "        bert_ids, bert_mask = get_words_index_seq(sample.SrcWords, batch_src_max_len)\n",
        "        src_words_list.append(bert_ids)#call get_words_index_seq():[list of word_index of length max_src_len]\n",
        "        bert_mask_list.append(bert_mask)\n",
        "        src_words_mask_list.append(get_padded_mask(sample.SrcLen, batch_src_max_len))#call get_padded_mask(): [0,0,0..till srclength,1,1,1,...till padded length]\n",
        "        src_char_seq.append(get_char_seq(sample.SrcWords, batch_src_max_len))#call get_char_seq(): [character index sequence with padded for CNN processing]\n",
        "        #cur_masked_adj = np.zeros((batch_src_max_len, batch_src_max_len), dtype=np.float32)#skip\n",
        "        #cur_masked_adj[:len(sample.SrcWords), :len(sample.SrcWords)] = sample.AdjMat#skip\n",
        "        #adj_lst.append(cur_masked_adj)#skip\n",
        "        positional_index_list.append(get_positional_index(len(sample.SrcWords), batch_src_max_len))#positional index of each word in the source sentence padded with 0\n",
        "        src_pos_tag_seq.append(get_pos_tag_index_seq(sample.PosTags, batch_src_max_len))#each element is [list of tag index of each word in the sentence of length max_src_len]\n",
        "        #src_ent_tag_seq.append(get_ent_tag_index_seq(sample.EntTags, batch_src_max_len))######\n",
        "        src_dep_tag_seq.append(get_dep_tag_index_seq(sample.DepTags, batch_src_max_len))\n",
        "        if is_training:\n",
        "            trigger_start_seq.append(get_padded_pointers_trig(sample.TrgPointers, 0, batch_trg_max_len))#list of all the start index of the tuple's event in a sentence with padding -1 (to max_trg_len)\n",
        "            trigger_end_seq.append(get_padded_pointers_trig(sample.TrgPointers, 1, batch_trg_max_len))#list of all the end index of the tuple's event in a sentence with pad -1 (to max_trg_len)\n",
        "            entity_start_seq.append(get_padded_pointers_arg(sample.TrgPointers, 2, batch_trg_max_len))#list of all the first index of the tuple's argument in a sequence with pad -1(to max_trg_len)\n",
        "            entity_end_seq.append(get_padded_pointers_arg(sample.TrgPointers, 3, batch_trg_max_len))#list of all the end index of the tuple's argument in a sentence with pad -1(to max_trg_len)\n",
        "            rel_seq.append(get_padded_relations(sample.TrgRels, batch_trg_max_len))#list of all the relation index(from rel_vocab) padded with 'NA' and '<Pad>'\n",
        "\n",
        "            event_seq.append(get_padded_events(sample.eventTypes, batch_trg_max_len))#list of all the event index(from event_vocab) padded with <Pad>'\n",
        "            arg_seq.append(get_padded_args(sample.argTypes, batch_trg_max_len))#list of all the event index(from event_vocab) padded with 'NA' and '<Pad>'\n",
        "\n",
        "            decoder_input_list.append(get_relation_index_seq(sample.TrgRels, batch_trg_max_len))#list of all the relation index(from rel_vocab) padded with 'None' and '<Pad>'\n",
        "\n",
        "            trigger_mask, entity_mask = get_entity_masks(sample.TrgPointers, batch_src_max_len, batch_trg_max_len)#list of length max_trg_len where each item is a list of size max_src_len. Each item of that list is mask where all but start and end index of entity_1 (and entity_2) set to 1 (respectively).\n",
        "            trigger_mask_seq.append(trigger_mask)\n",
        "            entity_mask_seq.append(entity_mask)\n",
        "        else:\n",
        "            decoder_input_list.append(get_relation_index_seq([], 1))\n",
        "\n",
        "    return {'src_words': np.array(src_words_list, dtype=np.float32),#list of word_index\n",
        "            'bert_mask': np.array(bert_mask_list),\n",
        "            'pos_tag_seq': np.array(src_pos_tag_seq),#list of pos tag index\n",
        "            #'ent_tag_seq': np.array(src_ent_tag_seq),#list of ent tag index (pad, unk, 0, 1)\n",
        "            'dep_tag_seq': np.array(src_dep_tag_seq),#list of dep tag index\n",
        "            'positional_seq': np.array(positional_index_list),#list of word_position_index\n",
        "            'src_words_mask': np.array(src_words_mask_list),#list of source word masks [0,0,0,1,1]\n",
        "            'src_chars': np.array(src_char_seq),#list of source character sequences with padding for CNN operation\n",
        "            'decoder_input': np.array(decoder_input_list),#list of all the relation indexes present in the trg_seq padded till amx_trg_len(for training), [] for testing\n",
        "            'event': np.array(event_seq),\n",
        "            'arg': np.array(arg_seq),\n",
        "            'rel': np.array(rel_seq),#list of relation seq padded till max_trg_len\n",
        "            'trigger_start':np.array(trigger_start_seq),#list of all the start index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'trigger_end': np.array(trigger_end_seq),#list of all the last index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'entity_start': np.array(entity_start_seq),#list of all the start index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'entity_end': np.array(entity_end_seq),#list of all the last index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'trigger_mask': np.array(trigger_mask_seq),#list of entity_1 mask, it's a list of size max_trg_len. and each item  is a list of size max_src_len, alll 1 but the entity_1's start and end pos is 0.\n",
        "            'entity_mask': np.array(entity_mask_seq)}#list of entity_2 mask,...\n"
      ],
      "metadata": {
        "id": "n8wARroZBc1p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WordEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, pre_trained_embed_matrix, drop_out_rate):\n",
        "        super(WordEmbeddings, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.embeddings.weight.data.copy_(torch.from_numpy(pre_trained_embed_matrix))\n",
        "        self.dropout = nn.Dropout(drop_out_rate)\n",
        "\n",
        "    def forward(self, words_seq):\n",
        "        word_embeds = self.embeddings(words_seq)\n",
        "        word_embeds = self.dropout(word_embeds)\n",
        "        return word_embeds\n",
        "\n",
        "    def weight(self):\n",
        "        return self.embeddings.weight\n"
      ],
      "metadata": {
        "id": "fHHtk2gSBhEk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, drop_out_rate):\n",
        "        super(CharEmbeddings, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(drop_out_rate)\n",
        "\n",
        "    def forward(self, words_seq):\n",
        "        char_embeds = self.embeddings(words_seq)\n",
        "        char_embeds = self.dropout(char_embeds)\n",
        "        return char_embeds\n",
        "\n"
      ],
      "metadata": {
        "id": "S_fStJRyBjjt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class POSEmbeddings(nn.Module):\n",
        "    def __init__(self, tag_len, tag_dim, drop_out_rate):\n",
        "        super(POSEmbeddings, self).__init__()\n",
        "        self.embeddings = nn.Embedding(tag_len, tag_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(drop_out_rate)\n",
        "\n",
        "    def forward(self, pos_seq):\n",
        "        pos_embeds = self.embeddings(pos_seq)\n",
        "        pos_embeds = self.dropout(pos_embeds)\n",
        "        return pos_embeds\n",
        "\n",
        "# class ENTEmbeddings(nn.Module):\n",
        "#     def __init__(self, tag_len, tag_dim, drop_out_rate):\n",
        "#         super(ENTEmbeddings, self).__init__()\n",
        "#         self.embeddings = nn.Embedding(tag_len, tag_dim, padding_idx=0)\n",
        "#         self.dropout = nn.Dropout(drop_out_rate)\n",
        "\n",
        "#     def forward(self, ent_seq):\n",
        "#         ent_embeds = self.embeddings(ent_seq)\n",
        "#         ent_embeds = self.dropout(ent_embeds)\n",
        "#         return ent_embeds\n",
        "\n",
        "class DEPEmbeddings(nn.Module):\n",
        "    def __init__(self, tag_len, tag_dim, drop_out_rate):\n",
        "        super(DEPEmbeddings, self).__init__()\n",
        "        self.embeddings = nn.Embedding(tag_len, tag_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(drop_out_rate)\n",
        "\n",
        "    def forward(self, dep_seq):\n",
        "        dep_embeds = self.embeddings(dep_seq)\n",
        "        dep_embeds = self.dropout(dep_embeds)\n",
        "        return dep_embeds\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.input_dim = input_dim#300\n",
        "        self.linear_ctx = nn.Linear(self.input_dim, self.input_dim, bias=False)\n",
        "        self.linear_query = nn.Linear(self.input_dim, self.input_dim, bias=True)\n",
        "        self.v = nn.Linear(self.input_dim, 1)\n",
        "\n",
        "    def forward(self, s_prev, enc_hs, src_mask):\n",
        "        uh = self.linear_ctx(enc_hs)\n",
        "        wq = self.linear_query(s_prev)\n",
        "        wquh = torch.tanh(wq + uh)\n",
        "        attn_weights = self.v(wquh).squeeze()\n",
        "        attn_weights.data.masked_fill_(src_mask.data, -float('inf'))\n",
        "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "        ctx = torch.bmm(attn_weights.unsqueeze(1), enc_hs).squeeze()\n",
        "        return ctx, attn_weights\n"
      ],
      "metadata": {
        "id": "hBYrHFUDBlxE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self, drop_out_rate):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        if not update_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.dropout = nn.Dropout(drop_out_rate)\n",
        "\n",
        "    def forward(self, input_ids, bert_mask, is_training=False):\n",
        "        seq_out = self.bert(input_ids, attention_mask=bert_mask)\n",
        "        seq_out = seq_out[0][:, 1:-1, :]\n",
        "        # seq_out = self.dropout(seq_out)\n",
        "        return seq_out\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers, is_bidirectional, drop_out_rate):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_dim = input_dim#768+char_emb+pos_emb\n",
        "        self.hidden_dim = hidden_dim#150\n",
        "        self.layers = layers#1\n",
        "        self.is_bidirectional = is_bidirectional#True\n",
        "        self.drop_rate = drop_out_rate#0.3\n",
        "        self.bert_vec = BERT(drop_out_rate)\n",
        "        #self.word_embeddings = WordEmbeddings(len(word_vocab), word_embed_dim, word_embed_matrix, drop_rate)\n",
        "        self.pos_embeddings = POSEmbeddings(len(pos_vocab), pos_embed_dim, drop_rate)\n",
        "        #self.ent_embeddings = ENTEmbeddings(len(ent_vocab), ent_emb_size, drop_rate)\n",
        "        self.char_embeddings = CharEmbeddings(len(char_vocab), char_embed_dim, drop_rate)\n",
        "        self.dep_embeddings = DEPEmbeddings(len(dep_vocab), dep_emb_size, drop_rate)\n",
        "        # self.pos_embeddings = nn.Embedding(max_positional_idx, positional_embed_dim, padding_idx=0)\n",
        "        if enc_type == 'LSTM':\n",
        "            self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.layers, batch_first=True,\n",
        "                                bidirectional=self.is_bidirectional, dropout=drop_out_rate)\n",
        "        '''\n",
        "        elif enc_type == 'GCN':\n",
        "            self.reduce_dim = nn.Linear(self.input_dim, 2 * self.hidden_dim)\n",
        "            self.gcn = GCN(gcn_num_layers, 2* self.hidden_dim, 2 * self.hidden_dim)\n",
        "\n",
        "        else:\n",
        "            self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.layers, batch_first=True,\n",
        "                                bidirectional=self.is_bidirectional)\n",
        "            self.gcn = GCN(gcn_num_layers, 2 * self.hidden_dim, 2 * self.hidden_dim)\n",
        "        '''\n",
        "\n",
        "        self.dropout = nn.Dropout(self.drop_rate)\n",
        "        self.conv1d = nn.Conv1d(char_embed_dim, char_feature_size, conv_filter_size)\n",
        "        self.max_pool = nn.MaxPool1d(max_word_len + conv_filter_size - 1, max_word_len + conv_filter_size - 1)\n",
        "        # self.mhc = 3\n",
        "        # self.mha = Multi_Head_Self_Attention(self.mhc, 2 * self.hidden_dim)\n",
        "\n",
        "    def forward(self, words, bert_mask, pos_tag_seq, dep_tag_seq, chars, pos_seq, is_training=False):\n",
        "        bert_embeds = self.bert_vec(words, bert_mask, is_training)\n",
        "        word_input = bert_embeds\n",
        "        #src_word_embeds = self.word_embeddings(words)#[bs, max_seq_len, emb_dim]\n",
        "        #custom_print(word_input.shape)\n",
        "        pos_embeds = self.pos_embeddings(pos_tag_seq)\n",
        "        #ent_embeds = self.ent_embeddings(ent_tag_seq)\n",
        "        dep_embeds = self.dep_embeddings(dep_tag_seq)\n",
        "        #custom_print(pos_embeds.shape)\n",
        "        # pos_embeds = self.dropout(self.pos_embeddings(pos_seq))\n",
        "        char_embeds = self.char_embeddings(chars)#[]\n",
        "        char_embeds = char_embeds.permute(0, 2, 1)#[bs, emb_dim, max_seq_len]\n",
        "\n",
        "        char_feature = torch.tanh(self.max_pool(self.conv1d(char_embeds)))\n",
        "        char_feature = char_feature.permute(0, 2, 1)\n",
        "        #custom_print(char_feature.shape)\n",
        "\n",
        "        words_input = torch.cat((word_input, pos_embeds,  dep_embeds), -1)#[bs, max_seq_len, emb_dim=350]\n",
        "        #custom_print(words_input.shape)\n",
        "\n",
        "        if enc_type == 'LSTM':\n",
        "            outputs, hc = self.lstm(words_input)\n",
        "        '''\n",
        "        elif enc_type == 'GCN':\n",
        "            outputs = self.reduce_dim(words_input)\n",
        "            outputs = self.gcn(outputs, adj)\n",
        "        else:\n",
        "            outputs, hc = self.lstm(words_input)\n",
        "            outputs = self.dropout(outputs)\n",
        "            outputs = self.gcn(outputs, adj)\n",
        "        '''\n",
        "        # outputs += pos_embeds\n",
        "        # outputs = self.mha(outputs, outputs, outputs)\n",
        "        #outputs = self.dropout(outputs)#(bs, seq_len, hid_dim)\n",
        "        outputs = self.dropout(words_input)#(bs, seq_len, hid_dim)\n",
        "        #custom_print(outputs.shape)\n",
        "        return outputs\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers, drop_out_rate, max_length):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layers = layers\n",
        "        self.drop_rate = drop_out_rate\n",
        "        self.max_length = max_length\n",
        "\n",
        "        if att_type == 0:\n",
        "            self.attention = Attention(input_dim)\n",
        "            self.lstm = nn.LSTMCell(10 * self.input_dim, self.hidden_dim)\n",
        "        elif att_type == 1:\n",
        "            # self.w = nn.Linear(9 * self.input_dim, self.input_dim)\n",
        "            self.attention = Attention(input_dim)\n",
        "            self.lstm = nn.LSTMCell(10 * self.input_dim, self.hidden_dim)\n",
        "        else:\n",
        "            # self.w = nn.Linear(9 * self.input_dim, self.input_dim)\n",
        "            self.attention1 = Attention(input_dim)\n",
        "            self.attention2 = Attention(input_dim)\n",
        "            self.lstm = nn.LSTMCell(10 * self.input_dim, self.hidden_dim)\n",
        "\n",
        "        self.trig_pointer_lstm = nn.LSTM(2 * self.input_dim, self.input_dim, 1, batch_first=True,\n",
        "                                       bidirectional=True)\n",
        "        self.ent_pointer_lstm = nn.LSTM(4 * self.input_dim, self.input_dim, 1, batch_first=True,\n",
        "                                       bidirectional=True)\n",
        "\n",
        "        #self.arg1s_lin = nn.Linear(2 * self.input_dim, 1)#trigger_s\n",
        "        self.trigger_s_lin = nn.Linear(2 * self.input_dim, 1)\n",
        "        #self.arg1e_lin = nn.Linear(2 * self.input_dim, 1)#trigger_e\n",
        "        self.trigger_e_lin = nn.Linear(2 * self.input_dim, 1)\n",
        "        #self.arg2s_lin = nn.Linear(2 * self.input_dim, 1)#entity_s\n",
        "        self.entity_s_lin = nn.Linear(2 * self.input_dim, 1)\n",
        "        #self.arg2e_lin = nn.Linear(2 * self.input_dim, 1)#entity_e\n",
        "        self.entity_e_lin = nn.Linear(2 * self.input_dim, 1)\n",
        "\n",
        "\n",
        "        self.et_lin = nn.Linear(5* self.input_dim, len(eventnameToIdx))#***************to identify the event type\n",
        "        self.argt_lin = nn.Linear(9* self.input_dim + len(eventnameToIdx), len(argnameToIdx))#***************to identify the argumwnt type\n",
        "\n",
        "        self.rel_lin = nn.Linear(9 * self.input_dim + len(eventnameToIdx), len(relnameToIdx))#to identify the role\n",
        "\n",
        "        self.dropout = nn.Dropout(self.drop_rate)\n",
        "        self.w = nn.Linear(8 * self.input_dim, self.input_dim)\n",
        "\n",
        "    def forward(self, prev_tuples, h_prev, enc_hs, src_mask, trigger, entity, trigger_mask, entity_mask,\n",
        "                is_training=False):\n",
        "\n",
        "        '''\n",
        "        y_prev= [bs, dec_hid_dim]\n",
        "        prev_tuples=[bs, 9*dec_hid_dim]\n",
        "        h_prev=([bs,dec_hid_dim],[bs,dec_hid_dim])\n",
        "        enc_hs=[bs,seq_len,dec_hid_dim]\n",
        "        src_mask=[bs,seq_len]\n",
        "        trigger=[bs,4*dec_hid_dim]\n",
        "        entity=[bs,4*dec_hid_dim]\n",
        "        trigger_mask=[bs, seq_len]\n",
        "        entity_mask=[bs, seq_len]\n",
        "        '''\n",
        "        src_time_steps = enc_hs.size()[1]\n",
        "\n",
        "        if att_type == 0:#not used\n",
        "            ctx, attn_weights = self.attention(h_prev[0].squeeze().unsqueeze(1).repeat(1, src_time_steps, 1),\n",
        "                                                enc_hs, src_mask)\n",
        "        elif att_type == 1:#not used\n",
        "            reduce_prev_tuples = self.w(prev_tuples)\n",
        "            ctx, attn_weights = self.attention(reduce_prev_tuples.unsqueeze(1).repeat(1, src_time_steps, 1),\n",
        "                                                enc_hs, src_mask)\n",
        "        else:\n",
        "            ctx1, attn_weights1 = self.attention1(h_prev[0].squeeze().unsqueeze(1).repeat(1, src_time_steps, 1),\n",
        "                                               enc_hs, src_mask)\n",
        "            reduce_prev_tuples = self.w(prev_tuples)\n",
        "            ctx2, attn_weights2 = self.attention2(reduce_prev_tuples.unsqueeze(1).repeat(1, src_time_steps, 1),\n",
        "                                               enc_hs, src_mask)\n",
        "            ctx = torch.cat((ctx1, ctx2), -1)#[bs,2*300]\n",
        "            attn_weights = (attn_weights1 + attn_weights2) / 2#[bs,src_seq_len]\n",
        "\n",
        "        s_cur = torch.cat((prev_tuples, ctx), 1)#[bs, 10*300]\n",
        "        hidden, cell_state = self.lstm(s_cur, h_prev)\n",
        "        hidden = self.dropout(hidden)#[bs, 300]\n",
        "\n",
        "        if use_hadamard:\n",
        "            enc_hs = enc_hs * attn_weights.unsqueeze(2)\n",
        "\n",
        "        trig_pointer_lstm_input = torch.cat((enc_hs, hidden.unsqueeze(1).repeat(1, src_time_steps, 1)), 2)#[bs, src_seq_len, 2*300]\n",
        "        trig_pointer_lstm_out, phc = self.trig_pointer_lstm(trig_pointer_lstm_input)\n",
        "        trig_pointer_lstm_out = self.dropout(trig_pointer_lstm_out)#[bs, src_seq_len, 2*300]\n",
        "\n",
        "        ent_pointer_lstm_input = torch.cat((trig_pointer_lstm_input, trig_pointer_lstm_out), 2)#[bs,src_seq_len, 4*300]\n",
        "        ent_pointer_lstm_out, phc = self.ent_pointer_lstm(ent_pointer_lstm_input)#\n",
        "        ent_pointer_lstm_out = self.dropout(ent_pointer_lstm_out)#[bs, src_seq_len, 2*300]\n",
        "\n",
        "        trig_s = self.trigger_s_lin(trig_pointer_lstm_out).squeeze()#[bs,src_seq_len]\n",
        "        trig_s.data.masked_fill_(src_mask.data, -float('inf'))\n",
        "\n",
        "        trig_e = self.trigger_e_lin(trig_pointer_lstm_out).squeeze()#[bs,src_seq_len]\n",
        "        trig_e.data.masked_fill_(src_mask.data, -float('inf'))\n",
        "\n",
        "        ent_s = self.entity_s_lin(ent_pointer_lstm_out).squeeze()#[bs,src_seq_len]\n",
        "        ent_s.data.masked_fill_(src_mask.data, -float('inf'))\n",
        "\n",
        "        ent_e = self.entity_e_lin(ent_pointer_lstm_out).squeeze()\n",
        "        ent_e.data.masked_fill_(src_mask.data, -float('inf'))#[bs,src_seq_len]\n",
        "\n",
        "        trig_s_weights = F.softmax(trig_s, dim=-1)#normaized probability of each word index to be the strat index of arg1\n",
        "        trig_e_weights = F.softmax(trig_e, dim=-1)#normaized probability of each word index to be the end index of arg1\n",
        "\n",
        "        trig_sv = torch.bmm(trig_e_weights.unsqueeze(1), trig_pointer_lstm_out).squeeze()#[bs,2*300]\n",
        "        trig_ev = torch.bmm(trig_s_weights.unsqueeze(1), trig_pointer_lstm_out).squeeze()#[bs, 2*300]\n",
        "        trig_et = self.dropout(torch.cat((trig_sv, trig_ev), -1))#[bs,4*300]#holds trigger and event type representation\n",
        "\n",
        "        ent_s_weights = F.softmax(ent_s, dim=-1)\n",
        "        ent_e_weights = F.softmax(ent_e, dim=-1)\n",
        "\n",
        "        ent_sv = torch.bmm(ent_e_weights.unsqueeze(1), ent_pointer_lstm_out).squeeze()#[bs, 2*300]\n",
        "        ent_ev = torch.bmm(ent_s_weights.unsqueeze(1), ent_pointer_lstm_out).squeeze()#[bs, 2*300]\n",
        "        ent_argt = self.dropout(torch.cat((ent_sv, ent_ev), -1))#[bs,4*300]\n",
        "\n",
        "        # enc_hs = self.mha(enc_hs, enc_hs, enc_hs)\n",
        "        # sent1 = self.mha1(enc_hs, arg1, src_mask)\n",
        "        # sent2 = self.mha2(enc_hs, arg2, src_mask)\n",
        "\n",
        "        # if is_training:\n",
        "        #     # arg1 = self.dropout(multi_head_pooling(mh_hid, arg1_mask, 'sum'))\n",
        "        #     # arg2 = self.dropout(multi_head_pooling(mh_hid, arg2_mask, 'sum'))\n",
        "        #\n",
        "        #     # src_mask = src_mask + arg1_mask.eq(0) + arg2_mask.eq(0)\n",
        "        #     # src_mask = src_mask.eq(0).eq(0)\n",
        "        #     sent = self.dropout(multi_head_pooling(mh_hid, src_mask, 'max'))\n",
        "        # else:\n",
        "        #     arg1_one_hot = F.gumbel_softmax(arg1s).byte() + F.gumbel_softmax(arg1e).byte()\n",
        "        #     arg2_one_hot = F.gumbel_softmax(arg2s).byte() + F.gumbel_softmax(arg2e).byte()\n",
        "        #     # arg1_mask = arg1_one_hot.eq(0)\n",
        "        #     # arg2_mask = arg2_one_hot.eq(0)\n",
        "        #\n",
        "        #     # arg1 = self.dropout(multi_head_pooling(mh_hid, arg1_mask, 'sum'))\n",
        "        #     # arg2 = self.dropout(multi_head_pooling(mh_hid, arg2_mask, 'sum'))\n",
        "        #\n",
        "        #     # src_mask = src_mask + arg1_one_hot + arg2_one_hot\n",
        "        #     # src_mask = src_mask.eq(0).eq(0)\n",
        "        #     sent = self.dropout(multi_head_pooling(mh_hid, src_mask, 'max'))\n",
        "\n",
        "\n",
        "        event_types = self.et_lin(torch.cat((trig_et, hidden),-1))#[bs, 9*300]--->[bs, 33]\n",
        "        #custom_print('event_types size={}'.format(event_types.shape))\n",
        "        arg_types = self.argt_lin(torch.cat((ent_argt, trig_et, hidden, event_types), -1))#[bs, 9*300]----> [bs, 7]\n",
        "        #custom_print('arg_types size={}'.format(arg_types.shape))\n",
        "        rel = self.rel_lin(torch.cat((hidden, trig_et, ent_argt, event_types), -1))#[bs,9*300]---->[bs, 36]\n",
        "        #custom_print('rel size={}'.format(rel.shape))\n",
        "\n",
        "        if is_training:\n",
        "            trig_s = F.log_softmax(trig_s, dim=-1)#[bs,max_src_len]\n",
        "            trig_e = F.log_softmax(trig_e, dim=-1)#[bs,max_src_len]\n",
        "            ent_s = F.log_softmax(ent_s, dim=-1)#[bs,max_src_len]\n",
        "            ent_e = F.log_softmax(ent_e, dim=-1)#[bs,max_src_len]\n",
        "            rel = F.log_softmax(rel, dim=-1)#[bs,max_rel_types]\n",
        "            event_types=F.log_softmax(event_types, dim=-1)#[bs, no_event_types]\n",
        "            arg_types=F.log_softmax(arg_types, dim=-1)#[bs, no_arg_types]\n",
        "\n",
        "            return rel.unsqueeze(1), trig_s.unsqueeze(1), trig_e.unsqueeze(1), ent_s.unsqueeze(1),  ent_e.unsqueeze(1), (hidden, cell_state), trig_et, ent_argt, event_types.unsqueeze(1), arg_types.unsqueeze(1)\n",
        "        else:\n",
        "            trig_s = F.softmax(trig_s, dim=-1)\n",
        "            trig_e = F.softmax(trig_e, dim=-1)\n",
        "            ent_s = F.softmax(ent_s, dim=-1)\n",
        "            ent_e = F.softmax(ent_e, dim=-1)\n",
        "            rel = F.softmax(rel, dim=-1)\n",
        "            event_types=F.log_softmax(event_types, dim=-1)#[bs, no_event_types]\n",
        "            arg_types=F.log_softmax(arg_types, dim=-1)#[bs, no_arg_types]\n",
        "            return rel.unsqueeze(1), trig_s.unsqueeze(1), trig_e.unsqueeze(1), ent_s.unsqueeze(1), ent_e.unsqueeze(1), (hidden, cell_state), trig_et, ent_argt, event_types.unsqueeze(1), arg_types.unsqueeze(1)\n",
        "\n",
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Seq2SeqModel, self).__init__()\n",
        "        self.encoder = Encoder(enc_inp_size, int(enc_hidden_size/2), 1, True, drop_rate)\n",
        "        self.decoder = Decoder(dec_inp_size, dec_hidden_size, 1, drop_rate, max_trg_len)\n",
        "        #self.relation_embeddings = nn.Embedding(len(relnameToIdx), word_embed_dim)\n",
        "        # self.w = nn.Linear(10 * dec_inp_size, dec_inp_size)\n",
        "        self.dropout = nn.Dropout(drop_rate)\n",
        "\n",
        "    def forward(self, src_words_seq, bert_mask, pos_tag_seq,dep_tag_seq, src_mask, src_char_seq, pos_seq, trg_words_seq, trg_rel_cnt,\n",
        "                trigger_mask, entity_mask, is_training=False):\n",
        "        #custom_print('src_word_seq = {}'.format(src_words_seq.shape))#[32, max_seq_len]\n",
        "        #if is_training:\n",
        "        #    trg_word_embeds = self.dropout(self.relation_embeddings(trg_words_seq))\n",
        "        #custom_print('src_word_seq = {}'.format(src_words_seq.shape))#[32, max_seq_len]\n",
        "        batch_len = src_words_seq.size()[0]#batch_size\n",
        "        #custom_print('batch_size={}'.format(batch_len))\n",
        "        #src_time_steps = src_words_seq.size()[1]#max_src_len in that batch\n",
        "        #custom_print('max_src_len={}'.format(src_time_steps))\n",
        "        time_steps = trg_rel_cnt#max_trg_len (max no of relations present in trg_seq in that batch)\n",
        "        #custom_print('time_step={}'.format(time_steps))\n",
        "        #print(src_words_seq.shape)\n",
        "        enc_hs = self.encoder(src_words_seq, bert_mask, pos_tag_seq,  dep_tag_seq, src_char_seq, pos_seq, is_training)#call encoder(): (bs, seq_len, hid_dim)\n",
        "        #custom_print(enc_hs.shape)\n",
        "        src_time_steps = enc_hs.shape[1]\n",
        "        #custom_print('max_src_len={}'.format(src_time_steps))\n",
        "        #custom_print('encoder output dim = {}'.format(enc_hs.shape))\n",
        "        #custom_print('source_mask={}'.format(src_mask.shape))\n",
        "        h0 = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, dec_hidden_size))).cuda()#[bs, 300]\n",
        "        c0 = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, dec_hidden_size))).cuda()#[bs, 300]\n",
        "        dec_hid = (h0, c0)\n",
        "\n",
        "        #dec_inp = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, dec_hidden_size))).cuda()#[bs, 300]\n",
        "        trigger = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, 4 * dec_hidden_size))).cuda()#[bs, 4*300]\n",
        "        entity = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, 4 * dec_hidden_size))).cuda()#[bs, 4*300]\n",
        "\n",
        "        prev_tuples = torch.cat((trigger, entity), -1)#[bs, 8*300]\n",
        "        #custom_print('start decoding.....')\n",
        "        if is_training:\n",
        "            dec_outs = self.decoder(prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity,\n",
        "                                    trigger_mask[:, 0, :].squeeze(), entity_mask[:, 0, :].squeeze(), is_training)\n",
        "        else:\n",
        "            dec_outs = self.decoder(prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity, None, None,\n",
        "                                    is_training)\n",
        "        rel = dec_outs[0]#[bs,1,no_of_rel_types]\n",
        "        trig_s = dec_outs[1]#[bs, 1, max_src_len]\n",
        "        trig_e = dec_outs[2]#[bs, 1, max_src_len]\n",
        "        ent_s = dec_outs[3]#[bs, 1, max_src_len]\n",
        "        ent_e = dec_outs[4]#[bs, 1, max_src_len]\n",
        "        dec_hid = dec_outs[5]#([bs, hid_dim],[bs, hid_dim])\n",
        "        trigger = dec_outs[6]#[bs, 4*300]\n",
        "        entity = dec_outs[7]#[bs, 4*300]\n",
        "        trg_type=dec_outs[8]#[bs, 1, no_eventTypes]\n",
        "        arg_type=dec_outs[9]#[bs, 1, no_argTypes]\n",
        "\n",
        "        topv, topi = rel[:, :, 1:].topk(1)#\n",
        "        topi = torch.add(topi, 1)\n",
        "        #custom_print('decoding continue...')\n",
        "        for t in range(1, time_steps):\n",
        "            #custom_print('time step: {}'.format(t))\n",
        "            if is_training:\n",
        "                #dec_inp = trg_word_embeds[:, t - 1, :].squeeze()#[bs, 300]\n",
        "                prev_tuples = torch.cat((trigger, entity), -1) + prev_tuples#[bs, 9*300]\n",
        "                dec_outs = self.decoder(prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity,\n",
        "                                        trigger_mask[:, t, :].squeeze(), entity_mask[:, t, :].squeeze(), is_training)\n",
        "            else:\n",
        "                #dec_inp = self.relation_embeddings(topi.squeeze().detach()).squeeze()\n",
        "                prev_tuples = torch.cat((trigger, entity), -1) + prev_tuples\n",
        "                dec_outs = self.decoder(prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity, None, None,\n",
        "                                        is_training)\n",
        "\n",
        "            cur_rel = dec_outs[0]\n",
        "            cur_trig_s = dec_outs[1]\n",
        "            cur_trig_e = dec_outs[2]\n",
        "            cur_ent_s = dec_outs[3]\n",
        "            cur_ent_e = dec_outs[4]\n",
        "            dec_hid = dec_outs[5]\n",
        "            trigger = dec_outs[6]\n",
        "            entity = dec_outs[7]\n",
        "            cur_trg_type=dec_outs[8]\n",
        "            cur_arg_type=dec_outs[9]\n",
        "\n",
        "            rel = torch.cat((rel, cur_rel), 1)\n",
        "            trig_s = torch.cat((trig_s, cur_trig_s), 1)\n",
        "            trig_e = torch.cat((trig_e, cur_trig_e), 1)\n",
        "            ent_s = torch.cat((ent_s, cur_ent_s), 1)\n",
        "            ent_e = torch.cat((ent_e, cur_ent_e), 1)\n",
        "            trg_type = torch.cat((trg_type, cur_trg_type),1)\n",
        "            arg_type = torch.cat((arg_type, cur_arg_type),1)\n",
        "\n",
        "            #topv, topi = cur_rel[:, :, 1:].topk(1)\n",
        "            #topi = torch.add(topi, 1)\n",
        "            rel_topv, rel_topi = cur_rel[:, :, 1:].topk(1)\n",
        "            rel_topi = torch.add(rel_topi, 1)\n",
        "            trg_topv, trg_topi = cur_trg_type[:, :, 1:].topk(1)\n",
        "            trg_topi = torch.add(trg_topi, 1)\n",
        "            arg_topv, arg_topi = cur_arg_type[:, :, 1:].topk(1)\n",
        "            arg_topi = torch.add(arg_topi, 1)\n",
        "        #custom_print('decoding complete')\n",
        "        #custom_print('rel shape={}'.format(rel.shape))\n",
        "        #custom_print('trig_s={}'.format(trig_s.shape))\n",
        "        #custom_print('trig_e={}'.format(trig_e.shape))\n",
        "        #custom_print('ent_s={}'.format(ent_s.shape))\n",
        "        #custom_print('ent_e={}'.format(ent_e.shape))\n",
        "        #custom_print('trg_type shape={}'.format(trg_type.shape))\n",
        "        #custom_print('arg_type shape={}'.format(arg_type.shape))\n",
        "        if is_training:\n",
        "            rel = rel.view(-1, len(relnameToIdx))\n",
        "            trig_s = trig_s.view(-1, src_time_steps)\n",
        "            trig_e = trig_e.view(-1, src_time_steps)\n",
        "            ent_s = ent_s.view(-1, src_time_steps)\n",
        "            ent_e = ent_e.view(-1, src_time_steps)\n",
        "            trg_type = trg_type.view(-1, len(eventnameToIdx))\n",
        "            arg_type = arg_type.view(-1, len(argnameToIdx))\n",
        "        #custom_print('execution complete for this batch')\n",
        "        return rel, trig_s, trig_e, ent_s, ent_e, trg_type, arg_type\n",
        "\n",
        "def get_model(model_id):\n",
        "    if model_id == 1:\n",
        "        return Seq2SeqModel()\n"
      ],
      "metadata": {
        "id": "lRWgejuLBo47"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(data):\n",
        "    #print(len(data))\n",
        "    custom_print(len(data))\n",
        "    data.sort(key=lambda x: x.SrcLen)\n",
        "    num_batch = int(len(data) / batch_size)\n",
        "    rand_idx = random.sample(range(num_batch), num_batch)\n",
        "    new_data = []\n",
        "    for idx in rand_idx:\n",
        "        new_data += data[batch_size * idx: batch_size * (idx + 1)]\n",
        "    if len(new_data) < len(data):\n",
        "        new_data += data[num_batch * batch_size:]\n",
        "    return new_data\n",
        "\n",
        "def predict(samples, model, model_id):\n",
        "    pred_batch_size = batch_size\n",
        "    batch_count = math.ceil(len(samples) / pred_batch_size)\n",
        "    move_last_batch = False\n",
        "    if len(samples) - batch_size * (batch_count - 1) == 1:\n",
        "        move_last_batch = True\n",
        "        batch_count -= 1\n",
        "    rel = list()\n",
        "    arg1s = list()\n",
        "    arg1e = list()\n",
        "    arg2s = list()\n",
        "    arg2e = list()\n",
        "    eType=list()\n",
        "    argType=list()\n",
        "    model.eval()\n",
        "    #set_random_seeds(random_seed)\n",
        "    torch.manual_seed(random_seed)\n",
        "    start_time = datetime.datetime.now()\n",
        "    for batch_idx in tqdm(range(0, batch_count)):\n",
        "        batch_start = batch_idx * pred_batch_size\n",
        "        batch_end = min(len(samples), batch_start + pred_batch_size)\n",
        "        if batch_idx == batch_count - 1 and move_last_batch:\n",
        "            batch_end = len(samples)\n",
        "\n",
        "        cur_batch = samples[batch_start:batch_end]\n",
        "        cur_samples_input = get_batch_data(cur_batch, False)\n",
        "\n",
        "        src_words_seq = torch.from_numpy(cur_samples_input['src_words'].astype('long'))\n",
        "        bert_words_mask = torch.from_numpy(cur_samples_input['bert_mask'].astype('bool'))\n",
        "        src_pos_tags = torch.from_numpy(cur_samples_input['pos_tag_seq'].astype('long'))\n",
        "        #src_ent_tags = torch.from_numpy(cur_samples_input['ent_tag_seq'].astype('long'))##\n",
        "        src_dep_tags = torch.from_numpy(cur_samples_input['dep_tag_seq'].astype('long'))\n",
        "        positional_seq = torch.from_numpy(cur_samples_input['positional_seq'].astype('long'))\n",
        "        src_words_mask = torch.from_numpy(cur_samples_input['src_words_mask'].astype('uint8'))\n",
        "        trg_words_seq = torch.from_numpy(cur_samples_input['decoder_input'].astype('long'))\n",
        "        src_chars_seq = torch.from_numpy(cur_samples_input['src_chars'].astype('long'))\n",
        "        #adj = torch.from_numpy(cur_samples_input['adj'].astype('float32'))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            src_words_seq = src_words_seq.cuda()\n",
        "            bert_words_mask = bert_words_mask.cuda()\n",
        "            src_pos_tags = src_pos_tags.cuda()\n",
        "            #src_ent_tags = src_ent_tags.cuda()\n",
        "            src_dep_tags = src_dep_tags.cuda()\n",
        "            src_words_mask = src_words_mask.cuda()\n",
        "            trg_words_seq = trg_words_seq.cuda()\n",
        "            src_chars_seq = src_chars_seq.cuda()\n",
        "            #adj = adj.cuda()\n",
        "            positional_seq = positional_seq.cuda()\n",
        "\n",
        "        src_words_seq = autograd.Variable(src_words_seq)\n",
        "        bert_words_mask = autograd.Variable(bert_words_mask)\n",
        "        src_pos_tags = autograd.Variable(src_pos_tags)\n",
        "        #src_ent_tags = autograd.Variable(src_ent_tags)\n",
        "        src_dep_tags = autograd.Variable(src_dep_tags)\n",
        "        src_words_mask = autograd.Variable(src_words_mask)\n",
        "        trg_words_seq = autograd.Variable(trg_words_seq)\n",
        "        src_chars_seq = autograd.Variable(src_chars_seq)\n",
        "        #adj = autograd.Variable(adj)\n",
        "        positional_seq = autograd.Variable(positional_seq)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if model_id == 1:\n",
        "                outputs = model(src_words_seq, bert_words_mask, src_pos_tags, src_dep_tags, src_words_mask, src_chars_seq, positional_seq, trg_words_seq,\n",
        "                                max_trg_len, None, None, False)\n",
        "\n",
        "        rel += list(outputs[0].data.cpu().numpy())\n",
        "        arg1s += list(outputs[1].data.cpu().numpy())\n",
        "        arg1e += list(outputs[2].data.cpu().numpy())\n",
        "        arg2s += list(outputs[3].data.cpu().numpy())\n",
        "        arg2e += list(outputs[4].data.cpu().numpy())\n",
        "        eType += list(outputs[5].data.cpu().numpy())\n",
        "        argType += list(outputs[6].data.cpu().numpy())\n",
        "        model.zero_grad()\n",
        "\n",
        "    end_time = datetime.datetime.now()\n",
        "    #print('Prediction time:', end_time - start_time)\n",
        "    custom_print('Prediction time:', end_time - start_time)\n",
        "    return rel, arg1s, arg1e, arg2s, arg2e, eType, argType\n",
        "\n",
        "def train_model(model_id, train_samples, dev_samples, best_model_file):\n",
        "    train_size = len(train_samples)\n",
        "    print('train_size')\n",
        "    print(train_size)\n",
        "    batch_count = int(math.ceil(train_size/batch_size))\n",
        "    move_last_batch = False\n",
        "    if len(train_samples) - batch_size * (batch_count - 1) == 1:\n",
        "        move_last_batch = True\n",
        "        batch_count -= 1\n",
        "    #print(batch_count)\n",
        "    custom_print(batch_count)\n",
        "    model = get_model(model_id)#call get_model(id=1)\n",
        "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    #print('Parameters size:', pytorch_total_params)\n",
        "    custom_print('Parameters size:', pytorch_total_params)\n",
        "    #print(model)\n",
        "    custom_print(model)\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    if n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    rel_criterion = nn.NLLLoss(ignore_index=0)\n",
        "\n",
        "    eType_criterion = nn.NLLLoss(ignore_index=0)#\n",
        "    aType_criterion = nn.NLLLoss(ignore_index=0)#\n",
        "\n",
        "    pointer_criterion = nn.NLLLoss(ignore_index=-1)\n",
        "    #event type classification loss***********\n",
        "    #arg type classification loss*************\n",
        "    #print('weight factor:', wf)\n",
        "    custom_print('weight factor:', wf)\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
        "    if update_bert:\n",
        "        optimizer = AdamW(model.parameters(), lr=1e-05, correct_bias=False)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
        "    #custom_print(optimizer)\n",
        "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    #print(optimizer)\n",
        "    custom_print(optimizer)\n",
        "    custom_print(sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "    best_dev_acc = -1.0\n",
        "    best_epoch_idx = -1\n",
        "    best_epoch_seed = -1\n",
        "    for epoch_idx in range(0, num_epoch):\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "        #print('Epoch:', epoch_idx + 1)\n",
        "        custom_print('Epoch:', epoch_idx + 1)\n",
        "        cur_seed = random_seed + epoch_idx + 1\n",
        "\n",
        "        torch.manual_seed(cur_seed)\n",
        "        #set_random_seeds(cur_seed)\n",
        "        cur_shuffled_train_data = shuffle_data(train_samples)#shuffle training data\n",
        "        start_time = datetime.datetime.now()\n",
        "        train_loss_val = 0.0\n",
        "\n",
        "        for batch_idx in tqdm(range(0, batch_count)):\n",
        "            batch_start = batch_idx * batch_size\n",
        "            batch_end = min(len(cur_shuffled_train_data), batch_start + batch_size)\n",
        "            if batch_idx == batch_count - 1 and move_last_batch:\n",
        "                batch_end = len(cur_shuffled_train_data)\n",
        "\n",
        "            cur_batch = cur_shuffled_train_data[batch_start:batch_end]\n",
        "            cur_samples_input = get_batch_data(cur_batch, True)#call get_batch_data()\n",
        "\n",
        "            '''\n",
        "            Each record of cur_samples_input{} holds\n",
        "            {'src_words': np.array(src_words_list, dtype=np.float32),#list of word_index\n",
        "            'positional_seq': np.array(positional_index_list),#list of word_position_index\n",
        "            'src_words_mask': np.array(src_words_mask_list),#list of source word masks [0,0,0,1,1]\n",
        "            'src_chars': np.array(src_char_seq),#list of source character sequences with padding for CNN operation\n",
        "            'decoder_input': np.array(decoder_input_list),#list of all the relation indexes present in the trg_seq padded till amx_trg_len(for training), [] for testing\n",
        "            'adj': np.array(adj_lst),\n",
        "            'rel': np.array(rel_seq),#list of relation seq padded till max_trg_len\n",
        "            'arg1_start':np.array(arg1_start_seq),#list of all the start index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'arg1_end': np.array(arg1_end_seq),#list of all the last index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'arg2_start': np.array(arg2_start_seq),#list of all the start index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'arg2_end': np.array(arg2_end_seq),#list of all the last index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
        "            'arg1_mask': np.array(arg1_mask_seq),#list of entity_1 mask, it's a list of size max_trg_len. and each item  is a list of size max_src_len, all 1 but the entity_1's start and end pos is 0.\n",
        "            'arg2_mask': np.array(arg2_mask_seq)}#list of entity_2 mask,...\n",
        "            }\n",
        "            '''\n",
        "\n",
        "            src_words_seq = torch.from_numpy(cur_samples_input['src_words'].astype('long'))#[23,45,1,56,78,..,0,0,..]\n",
        "            bert_words_mask = torch.from_numpy(cur_samples_input['bert_mask'].astype('bool'))\n",
        "            src_pos_tags = torch.from_numpy(cur_samples_input['pos_tag_seq'].astype('long'))##\n",
        "            #src_ent_tags = torch.from_numpy(cur_samples_input['ent_tag_seq'].astype('long'))##\n",
        "            src_dep_tags = torch.from_numpy(cur_samples_input['dep_tag_seq'].astype('long'))\n",
        "            positional_seq = torch.from_numpy(cur_samples_input['positional_seq'].astype('long'))#[1,2,3,4,..,0,0,...]\n",
        "            src_words_mask = torch.from_numpy(cur_samples_input['src_words_mask'].astype('bool'))#[0,0,0,0,0,1,1,1,..]\n",
        "            trg_words_seq = torch.from_numpy(cur_samples_input['decoder_input'].astype('long'))#[2,5,1,6,id('none'),id(pad),id(pad),..]\n",
        "            src_chars_seq = torch.from_numpy(cur_samples_input['src_chars'].astype('long'))#[0,0,3,4,5,0,0,12,2,3,4,0,0,....]\n",
        "            et_seq=torch.from_numpy(cur_samples_input['event'])#\n",
        "            arg_seq=torch.from_numpy(cur_samples_input['arg'])#\n",
        "            rel = torch.from_numpy(cur_samples_input['rel'].astype('long'))#same as trg_words_seq\n",
        "            trigger_s = torch.from_numpy(cur_samples_input['trigger_start'].astype('long'))#[3,3,7,-1,-1,-1,..]\n",
        "            trigger_e = torch.from_numpy(cur_samples_input['trigger_end'].astype('long'))#[5,5,10,-1,-1,-1,..]\n",
        "            entity_s = torch.from_numpy(cur_samples_input['entity_start'].astype('long'))#[9,9,14,-1,-1,..]\n",
        "            entity_e = torch.from_numpy(cur_samples_input['entity_end'].astype('long'))#[12,12,17,-1,-1,-1,..]\n",
        "\n",
        "            trigger_mask = torch.from_numpy(cur_samples_input['trigger_mask'].astype('uint8'))# [[0,0,1,1,1,1,1,1,..],[1,1,0,1,1,0,1,1...],[...]]\n",
        "            entity_mask = torch.from_numpy(cur_samples_input['entity_mask'].astype('uint8'))# [[1,1,0,0,1,1,1,1,..],[1,1,0,1,0,1,1,1...],[...]]\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                src_words_seq = src_words_seq.cuda()\n",
        "                bert_words_mask = bert_words_mask.cuda()\n",
        "                src_pos_tags = src_pos_tags.cuda()\n",
        "                #src_ent_tags = src_ent_tags.cuda()\n",
        "                src_dep_tags = src_dep_tags.cuda()\n",
        "                src_words_mask = src_words_mask.cuda()\n",
        "                trg_words_seq = trg_words_seq.cuda()\n",
        "                src_chars_seq = src_chars_seq.cuda()\n",
        "                #adj = adj.cuda()\n",
        "                positional_seq = positional_seq.cuda()\n",
        "\n",
        "                rel = rel.cuda()\n",
        "                et_seq = et_seq.cuda()\n",
        "                arg_seq = arg_seq.cuda()\n",
        "\n",
        "                trigger_s = trigger_s.cuda()\n",
        "                trigger_e = trigger_e.cuda()\n",
        "                entity_s = entity_s.cuda()\n",
        "                entity_e = entity_e.cuda()\n",
        "\n",
        "                trigger_mask = trigger_mask.cuda()\n",
        "                entity_mask = entity_mask.cuda()\n",
        "\n",
        "            src_words_seq = autograd.Variable(src_words_seq)\n",
        "            bert_words_mask = autograd.Variable(bert_words_mask)\n",
        "            src_pos_tags = autograd.Variable(src_pos_tags)\n",
        "            #src_ent_tags = autograd.Variable(src_ent_tags)\n",
        "            src_dep_tags = autograd.Variable(src_dep_tags)\n",
        "            src_words_mask = autograd.Variable(src_words_mask)\n",
        "            trg_words_seq = autograd.Variable(trg_words_seq)\n",
        "            src_chars_seq = autograd.Variable(src_chars_seq)\n",
        "            #adj = autograd.Variable(adj)\n",
        "            positional_seq = autograd.Variable(positional_seq)\n",
        "\n",
        "            rel = autograd.Variable(rel)\n",
        "            et_seq = autograd.Variable(et_seq)#\n",
        "            arg_seq = autograd.Variable(arg_seq)#\n",
        "            trigger_s = autograd.Variable(trigger_s)\n",
        "            trigger_e = autograd.Variable(trigger_e)\n",
        "            entity_s = autograd.Variable(entity_s)\n",
        "            entity_e = autograd.Variable(entity_e)\n",
        "\n",
        "            trigger_mask = autograd.Variable(trigger_mask)\n",
        "            entity_mask = autograd.Variable(entity_mask)\n",
        "\n",
        "\n",
        "            #print('src_words_seq = {}'.format(src_words_seq.shape))#[32,max_seq_len]\n",
        "            #print('bert_words_mask = {}'.format(bert_words_mask.shape))\n",
        "            #print('pos tags = {}'.format(src_pos_tags.shape))\n",
        "            #print('rel = {}'.format(rel.shape))\n",
        "            #print('trigger_s = {}'.format(trigger_s.shape))\n",
        "            #print('source_mask={}'.format(src_words_mask.shape))\n",
        "\n",
        "            #if model_id == 1:\n",
        "\n",
        "            outputs = model(src_words_seq, bert_words_mask, src_pos_tags, src_dep_tags, src_words_mask, src_chars_seq, positional_seq, trg_words_seq, rel.size()[1], trigger_mask, entity_mask, True)# call seq2seqmodel()\n",
        "\n",
        "            rel = rel.view(-1, 1).squeeze()\n",
        "            arg1s = trigger_s.view(-1, 1).squeeze()\n",
        "            arg1e = trigger_e.view(-1, 1).squeeze()\n",
        "            arg2s = entity_s.view(-1, 1).squeeze()\n",
        "            arg2e = entity_e.view(-1, 1).squeeze()\n",
        "            et_seq = et_seq.view(-1, 1).squeeze()#\n",
        "            arg_seq = arg_seq.view(-1, 1).squeeze()#\n",
        "\n",
        "            loss = rel_criterion(outputs[0], rel) + eType_criterion(outputs[5], et_seq) + aType_criterion(outputs[6], arg_seq) +   wf * (pointer_criterion(outputs[1], arg1s) + pointer_criterion(outputs[2], arg1e)) +  wf * (pointer_criterion(outputs[3], arg2s) + pointer_criterion(outputs[4], arg2e))\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
        "            if (batch_idx + 1) % update_freq == 0:\n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "            train_loss_val += loss.item()\n",
        "\n",
        "        train_loss_val /= batch_count\n",
        "        end_time = datetime.datetime.now()\n",
        "        #print('Training loss:', train_loss_val)\n",
        "        #print('Training time:', end_time - start_time)\n",
        "        custom_print('Training loss:', train_loss_val)\n",
        "        custom_print('Training time:', end_time - start_time)\n",
        "\n",
        "        #print('\\nDev Results\\n')\n",
        "        custom_print('\\nDev Results\\n')\n",
        "        #set_random_seeds(random_seed)\n",
        "        torch.manual_seed(cur_seed)#newly added\n",
        "\n",
        "        dev_preds = predict(dev_samples, model, model_id)# call predict()\n",
        "\n",
        "        pred_pos, gt_pos, correct_pos = get_F1(dev_samples, dev_preds)\n",
        "        #print(pred_pos, '\\t', gt_pos, '\\t', correct_pos)\n",
        "        custom_print(pred_pos, '\\t', gt_pos, '\\t', correct_pos)\n",
        "        p = float(correct_pos) / (pred_pos + 1e-8)\n",
        "        r = float(correct_pos) / (gt_pos + 1e-8)\n",
        "        dev_acc = (2 * p * r) / (p + r + 1e-8)\n",
        "        #print('F1:', dev_acc)\n",
        "        custom_print('F1:', dev_acc)\n",
        "\n",
        "        if dev_acc >= best_dev_acc:\n",
        "            best_epoch_idx = epoch_idx + 1\n",
        "            best_epoch_seed = cur_seed\n",
        "            #custom_print('model saved......')\n",
        "            #print('model saved......')\n",
        "            custom_print('model saved......')\n",
        "            best_dev_acc = dev_acc\n",
        "            torch.save(model.state_dict(), best_model_file)\n",
        "\n",
        "        #print('\\n\\n')\n",
        "        custom_print('\\n\\n')\n",
        "        if epoch_idx + 1 - best_epoch_idx >= early_stop_cnt:\n",
        "            break\n",
        "\n",
        "    #print('*******')\n",
        "    #print('Best Epoch:', best_epoch_idx)\n",
        "    #print('Best Epoch Seed:', best_epoch_seed)\n",
        "\n",
        "    custom_print('*******')\n",
        "    custom_print('Best Epoch:', best_epoch_idx)\n",
        "    custom_print('Best Epoch Seed:', best_epoch_seed)\n"
      ],
      "metadata": {
        "id": "zUWes1eABvtM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D5c1UKx3owC",
        "outputId": "74660994-e1f0-4c72-8845-0009450dbde5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gpu = torch.cuda.device_count()\n",
        "random_seed=1023\n",
        "torch.manual_seed(random_seed)\n",
        "#set_random_seeds(random_seed)\n",
        "batch_size = 8\n",
        "num_epoch = 15\n",
        "model_name=1\n",
        "\n",
        "logger = open('/content/drive/My Drive/NLP_Term_Project/training-lstm.log', 'w+')"
      ],
      "metadata": {
        "id": "ejAXMcS5B3se"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_base_size = 768\n",
        "update_bert = 0\n",
        "bert_model_name = 'bert-base-cased'\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_basic_tokenize=False)"
      ],
      "metadata": {
        "id": "KmRwnnESCl40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8c54b86e79114e78af92a229fd40e298",
            "05f7ed81ad7346758a7b71eaef5dbe52",
            "a5916dc7e87844b2b582cb790638db55",
            "dc56be297cad499eaca6ef0c56aff181",
            "70973fd805f74cfaa6ad8a52772c6107",
            "719eafce4b114edfba31c2afce7735f4",
            "aff8ae144d6d416db8d25d4d3a1b3d1a",
            "1f74cc01c4af44b7a52b51a6073f09e9",
            "3084b228e99343b3818c9e622c054735",
            "4d951523fca94a62ad8e006a5bd88ad9",
            "348c45ecc3c243079ce4b831af106bff",
            "9a3259d66caf492c86a715206b340cb9",
            "275f1f9b72194e159a256661f639be6a",
            "c6ed2c5e9fa2468c8c6185c86f03b929",
            "e6982dfcfac7495ab544b2e6bce4328b",
            "65bb4b7fc411449eb3ac379839407783",
            "96dc9eaf44a34e7f97f878df78b68d9b",
            "bc1bf6867c8b4323a0d88a8043c73821",
            "a39ceecccbdf4587a4859b0b389f4bd3",
            "4c9474cd6d3d44d6868dd3eaebee3514",
            "d67f1b3fbc054149b22f196f0e6ae950",
            "27008ebd869441898525426d7527f03c",
            "ef3f099810414e58a2b4c497fe6b7c05",
            "2dce436c2729449f844009a154650eb8",
            "c5a9f763762e45adab214a3d3f3b05b6",
            "dd1237aef3724779a7fd8805e9db6590",
            "824c1bfa13b1458b90b3d2ac133e1ca8",
            "3fe6a0dbc1eb4489bab2553f05466746",
            "27c11831838b4f6cabcc6b423bcb74ba",
            "6bbe100ccd124f9eb7ae47a57e382f70",
            "f522cfe4483e48c2b0bfaa1ff3bea689",
            "dfe319f5ab0d4da695b4ce63507a306d",
            "9f1049c0e682498c8397589ea10a5673"
          ]
        },
        "outputId": "9bd1fb28-9146-4fa6-ece6-b7dba6c491e1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c54b86e79114e78af92a229fd40e298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a3259d66caf492c86a715206b340cb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef3f099810414e58a2b4c497fe6b7c05"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_src_len = 200 #max sentence length = 200\n",
        "max_trg_len = 24 #max number of tuple\n",
        "embedding_file = '/content/drive/My Drive/glove.6B.300d.txt' #pretrained word embeddings file\n",
        "word_embed_dim = 300"
      ],
      "metadata": {
        "id": "G7O0U9osCpbF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_min_freq = 3\n",
        "\n",
        "char_embed_dim = 30\n",
        "char_feature_size = 30\n",
        "pos_embed_dim= 30\n",
        "dep_emb_size = 30\n",
        "conv_filter_size = 3\n",
        "max_word_len = 10\n",
        "#positional_embed_dim = word_embed_dim\n",
        "#max_positional_idx = 100\n",
        "max_positional_idx = 140\n",
        "\n",
        "enc_inp_size = bert_base_size + pos_embed_dim  + dep_emb_size\n",
        "enc_hidden_size = enc_inp_size\n",
        "dec_inp_size = enc_hidden_size\n",
        "dec_hidden_size = dec_inp_size\n",
        "\n",
        "drop_rate = 0.5\n",
        "enc_type = ['LSTM', 'GCN', 'LSTM-GCN'][0]\n",
        "att_type = 2\n",
        "wf = 1.0\n",
        "update_freq = 1\n",
        "use_hadamard = False\n",
        "early_stop_cnt = 7\n",
        "\n",
        "Sample = recordclass(\"Sample\", \"Id SrcLen SrcWords PosTags DepTags TrgLen TrgRels eventTypes argTypes TrgPointers\")\n",
        "rel_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/role.txt'\n",
        "relnameToIdx, relIdxToName = get_relations(rel_file) #return relation dictionary\n",
        "event_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/event_type.txt'\n",
        "eventnameToIdx, eventIdxToName=get_events(event_file) #return event dictionary\n",
        "arg_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/ent_type.txt'\n",
        "argnameToIdx, argIdxToName=get_arguments(arg_file) #return arg dictionary\n",
        "\n",
        "custom_print(max_src_len, '\\t', max_trg_len, '\\t', drop_rate)\n",
        "custom_print(batch_size, '\\t', num_epoch)\n",
        "custom_print(enc_type)\n",
        "custom_print('loading data......')\n",
        "\n",
        "src_train_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/train/train_bert_sent.txt'\n",
        "trg_train_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/train/train_bert_pointer.txt'\n",
        "pos_train_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/train/train_bert_pos.txt'\n",
        "#ent_train_file = 'train_bert.ent'\n",
        "dep_train_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/train/train_bert_dep.txt'\n",
        "\n",
        "train_data = read_data(src_train_file, trg_train_file, pos_train_file,dep_train_file, 1)#call read_data() for train_set\n",
        "\n",
        "src_dev_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/dev/dev_bert_sent.txt'\n",
        "trg_dev_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/dev/dev_bert_pointer.txt'\n",
        "pos_dev_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/dev/dev_bert_pos.txt'\n",
        "#ent_dev_file = 'dev_bert.ent'\n",
        "dep_dev_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/dev/dev_bert_dep.txt'\n",
        "dev_data = read_data(src_dev_file, trg_dev_file, pos_dev_file, dep_dev_file, 2)#call read_data() for dev_set\n",
        "\n",
        "src_test_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_sent.txt'\n",
        "trg_test_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_pointer.txt'\n",
        "pos_test_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_pos.txt'\n",
        "#ent_test_file = 'test_bert.ent'\n",
        "dep_test_file = '/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_dep.txt'\n",
        "test_data = read_data(src_test_file, trg_test_file, pos_test_file, dep_test_file, 3)#call read_data() for dev_set\n",
        "\n",
        "custom_print('Training data size:', len(train_data))\n",
        "custom_print('Development data size:', len(dev_data))\n",
        "\n",
        "custom_print(\"preparing vocabulary......\")\n",
        "\n",
        "save_vocab = '/content/drive/My Drive/NLP_Term_Project/vocab.pkl'\n",
        "custom_print(\"getting pos tags......\")\n",
        "#print(\"getting pos tags......\")\n",
        "pos_vocab = build_tags(pos_train_file, pos_dev_file, pos_test_file)\n",
        "#ent_vocab = build_tags(ent_train_file, ent_dev_file, ent_test_file)\n",
        "dep_vocab = build_tags(dep_train_file, dep_dev_file, dep_test_file)\n",
        "\n",
        "word_vocab, char_vocab, word_embed_matrix = build_vocab(train_data, dev_data, test_data, save_vocab, embedding_file)#create vocabulary and word embeddings\n",
        "\n",
        "#print(\"Training started......\")\n",
        "custom_print(\"Training started......\")\n",
        "\n",
        "model_name=1\n",
        "model_file_name = 'model_bert_lstm.h5py'\n",
        "model_file_path = F\"content/drive/My Drive/NLP_Term_Project/{model_file_name}\" \n",
        "\n",
        "\n",
        "train_model(model_name, train_data, dev_data, model_file_name)#call train_model()\n",
        "logger.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d8f84d3aba3d4f5cb235f36184f36432",
            "4143fcc31a5843dea68389b0efedbea5",
            "4a124021663542c3849ed697f0aa1e22",
            "848a0546dc0548bc90cbcb1183c42f16",
            "aba48648c27f446c85ef8486fbe1be71",
            "b88eab098b2e4a278c2d52ab5a483908",
            "9427bea9aa21430da6e16dc2b53cea59",
            "030f0af36d814989994f80535ddfc928",
            "418b3523c1f242ce882fde60a5fb4e81",
            "c4f2585016794ab4abb7a28b1f7e0024",
            "0a520f89d7544ccab5cf3b3be417bdd3"
          ]
        },
        "id": "yznxoVtdCuW2",
        "outputId": "4295e51b-1c0e-497a-ed49-7632b4fbd341"
      },
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200  \t  24  \t  0.5\n",
            "8  \t  15\n",
            "LSTM\n",
            "loading data......\n",
            "Training data size:  761\n",
            "Development data size:  182\n",
            "preparing vocabulary......\n",
            "getting pos tags......\n",
            "vocab length:  9409\n",
            "embed dictionary length:  4465\n",
            "Training started......\n",
            "train_size\n",
            "761\n",
            "95\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8f84d3aba3d4f5cb235f36184f36432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters size:  86737335\n",
            "Seq2SeqModel(\n",
            "  (encoder): Encoder(\n",
            "    (bert_vec): BERT(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (pos_embeddings): POSEmbeddings(\n",
            "      (embeddings): Embedding(20, 30, padding_idx=0)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (char_embeddings): CharEmbeddings(\n",
            "      (embeddings): Embedding(99, 30, padding_idx=0)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (dep_embeddings): DEPEmbeddings(\n",
            "      (embeddings): Embedding(47, 30, padding_idx=0)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (lstm): LSTM(828, 414, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (conv1d): Conv1d(30, 30, kernel_size=(3,), stride=(1,))\n",
            "    (max_pool): MaxPool1d(kernel_size=12, stride=12, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (attention1): Attention(\n",
            "      (linear_ctx): Linear(in_features=828, out_features=828, bias=False)\n",
            "      (linear_query): Linear(in_features=828, out_features=828, bias=True)\n",
            "      (v): Linear(in_features=828, out_features=1, bias=True)\n",
            "    )\n",
            "    (attention2): Attention(\n",
            "      (linear_ctx): Linear(in_features=828, out_features=828, bias=False)\n",
            "      (linear_query): Linear(in_features=828, out_features=828, bias=True)\n",
            "      (v): Linear(in_features=828, out_features=1, bias=True)\n",
            "    )\n",
            "    (lstm): LSTMCell(8280, 828)\n",
            "    (trig_pointer_lstm): LSTM(1656, 828, batch_first=True, bidirectional=True)\n",
            "    (ent_pointer_lstm): LSTM(3312, 828, batch_first=True, bidirectional=True)\n",
            "    (trigger_s_lin): Linear(in_features=1656, out_features=1, bias=True)\n",
            "    (trigger_e_lin): Linear(in_features=1656, out_features=1, bias=True)\n",
            "    (entity_s_lin): Linear(in_features=1656, out_features=1, bias=True)\n",
            "    (entity_e_lin): Linear(in_features=1656, out_features=1, bias=True)\n",
            "    (et_lin): Linear(in_features=4140, out_features=37, bias=True)\n",
            "    (argt_lin): Linear(in_features=7489, out_features=3, bias=True)\n",
            "    (rel_lin): Linear(in_features=7489, out_features=16, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (w): Linear(in_features=6624, out_features=828, bias=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "weight factor:  1.0\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 1e-05\n",
            ")\n",
            "195047607\n",
            "Epoch:  1\n",
            "761\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 95/95 [05:02<00:00,  3.19s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss:  15.74865436553955\n",
            "Training time:  0:05:02.813433\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:182: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:185: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:188: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:191: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:1239.)\n",
            "100%|██████████| 23/23 [01:16<00:00,  3.32s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction time:  0:01:16.442497\n",
            "652\n",
            "652  \t  1345  \t  34\n",
            "F1:  0.03405107221669818\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "761\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 95/95 [05:13<00:00,  3.30s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss:  12.097764838369269\n",
            "Training time:  0:05:13.253009\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction time:  0:01:16.030495\n",
            "943\n",
            "943  \t  1345  \t  94\n",
            "F1:  0.08216782732146542\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:12<00:00,  3.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  11.008498834308826\n",
            "Training time:  0:05:12.440174\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.287685\n",
            "1128\n",
            "1128  \t  1345  \t  134\n",
            "F1:  0.10837039536111581\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:07<00:00,  3.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  10.305366837350945\n",
            "Training time:  0:05:07.580498\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.200468\n",
            "1017\n",
            "1017  \t  1345  \t  183\n",
            "F1:  0.15495342439231183\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  5\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:13<00:00,  3.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  9.787271574923867\n",
            "Training time:  0:05:13.285080\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:15<00:00,  3.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:15.962874\n",
            "1120\n",
            "1120  \t  1345  \t  228\n",
            "F1:  0.18498985305232787\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  6\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:11<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  9.362766577068127\n",
            "Training time:  0:05:11.695970\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:15<00:00,  3.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:15.788210\n",
            "1108\n",
            "1108  \t  1345  \t  231\n",
            "F1:  0.18834080222002608\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  7\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:07<00:00,  3.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  9.05609467155055\n",
            "Training time:  0:05:07.493282\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.090276\n",
            "1051\n",
            "1051  \t  1345  \t  273\n",
            "F1:  0.22787979473949013\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  8\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:12<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  8.710852241516113\n",
            "Training time:  0:05:12.025461\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:15<00:00,  3.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.007152\n",
            "1027\n",
            "1027  \t  1345  \t  234\n",
            "F1:  0.19730185006290735\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  9\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:11<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  8.388215220601936\n",
            "Training time:  0:05:11.644795\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.149615\n",
            "1002\n",
            "1002  \t  1345  \t  256\n",
            "F1:  0.21815082595282242\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  10\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:12<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  8.17795151158383\n",
            "Training time:  0:05:12.054325\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.365712\n",
            "1087\n",
            "1087  \t  1345  \t  301\n",
            "F1:  0.24753288979107727\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  11\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:12<00:00,  3.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  7.964403674477025\n",
            "Training time:  0:05:12.848289\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.089391\n",
            "1098\n",
            "1098  \t  1345  \t  361\n",
            "F1:  0.29553826766432845\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  12\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:12<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  7.579523402766178\n",
            "Training time:  0:05:12.081976\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.206205\n",
            "1039\n",
            "1039  \t  1345  \t  371\n",
            "F1:  0.31124160581802\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  13\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:11<00:00,  3.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  7.523083977950247\n",
            "Training time:  0:05:11.131316\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.247342\n",
            "1138\n",
            "1138  \t  1345  \t  349\n",
            "F1:  0.28111155363095564\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  14\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:13<00:00,  3.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  7.3467427554883455\n",
            "Training time:  0:05:13.884588\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.167021\n",
            "1143\n",
            "1143  \t  1345  \t  391\n",
            "F1:  0.31430867670245805\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  15\n",
            "761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95/95 [05:13<00:00,  3.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  7.099076971254851\n",
            "Training time:  0:05:13.162014\n",
            "\n",
            "Dev Results\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [01:16<00:00,  3.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time:  0:01:16.288377\n",
            "1050\n",
            "1050  \t  1345  \t  378\n",
            "F1:  0.31565761511497603\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "*******\n",
            "Best Epoch:  15\n",
            "Best Epoch Seed:  1038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.move(\"/content/model_bert_lstm.h5py\", \"/content/drive/My Drive/NLP_Term_Project\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ayrPb-nQsbGG",
        "outputId": "d7520d9f-4e0e-4864-bfd5-b65c39c4cf6d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/NLP_Term_Project/model_bert_lstm.h5py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIm3kOwBuod0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}