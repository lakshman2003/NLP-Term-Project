{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmiUVpQpvDsC",
        "outputId": "f4a71614-f8d2-4b93-e65f-6a2d8006083e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sent_length = 200"
      ],
      "metadata": {
        "id": "fMVyHwsLjEGQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Hro01QxEu_-B"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/bert_data/test/test_bert_sent.txt','r') as file:\n",
        "  sentences = file.readlines()\n",
        "  sentences = [x.strip() for x in sentences]\n",
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_sent.txt','a') as file:\n",
        "  for sentence in sentences:\n",
        "    words = sentence.strip().split(' ')\n",
        "    new_sentence = words[:max_sent_length]\n",
        "    new_sentence = \" \".join(new_sentence)\n",
        "    file.write(new_sentence+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/bert_data/test/test_bert_pos.txt','r') as file:\n",
        "  sentences = file.readlines()\n",
        "  sentences = [x.strip() for x in sentences]\n",
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_pos.txt','a') as file:\n",
        "  for sentence in sentences:\n",
        "    words = sentence.strip().split(' ')\n",
        "    new_sentence = words[:max_sent_length]\n",
        "    new_sentence = \" \".join(new_sentence)\n",
        "    file.write(new_sentence+'\\n')"
      ],
      "metadata": {
        "id": "io3aqUq0v6_H"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/bert_data/test/test_bert_dep.txt','r') as file:\n",
        "  sentences = file.readlines()\n",
        "  sentences = [x.strip() for x in sentences]\n",
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_dep.txt','a') as file:\n",
        "  for sentence in sentences:\n",
        "    words = sentence.strip().split(' ')\n",
        "    new_sentence = words[:max_sent_length]\n",
        "    new_sentence = \" \".join(new_sentence)\n",
        "    file.write(new_sentence+'\\n')"
      ],
      "metadata": {
        "id": "jsgozYZgxpNn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/bert_data/test/test_bert_pointer.txt','r') as file:\n",
        "  pointers = file.readlines()\n",
        "  pointers = [x.strip() for x in pointers]\n",
        "with open('/content/drive/My Drive/NLP_Term_Project/dataset/english_ee/model_data/test/test_bert_pointer.txt','a') as file:\n",
        "  for sent_pointers in pointers:\n",
        "    tuples = sent_pointers.split(\" | \")\n",
        "    #print(tuples)\n",
        "    truncated_tuples = []\n",
        "    for tuple in tuples:\n",
        "      elements = tuple.split(\" \")\n",
        "      if(len(elements) != 7):\n",
        "        continue\n",
        "      #print(elements)\n",
        "      e_s = int(elements[0])\n",
        "      e_e = int(elements[1])\n",
        "      a_s = int(elements[3])\n",
        "      a_e = int(elements[4])\n",
        "      if(e_s>=max_sent_length or e_e>=max_sent_length or a_s>=max_sent_length or a_e>=max_sent_length):\n",
        "        continue\n",
        "      truncated_tuples.append(tuple)\n",
        "    output_tuples = \" | \".join(truncated_tuples)\n",
        "    #output_tuples = output_tuples[:-3]\n",
        "    file.write(output_tuples+'\\n')"
      ],
      "metadata": {
        "id": "edg7S_t6wdLO"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}